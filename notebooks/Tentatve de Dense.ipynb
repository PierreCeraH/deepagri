{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be5ebf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:41:46.240101Z",
     "start_time": "2022-03-04T14:41:46.220786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce871a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:33:53.289476Z",
     "start_time": "2022-03-04T14:33:52.270285Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9d3f37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:42:22.592214Z",
     "start_time": "2022-03-04T14:41:47.408458Z"
    }
   },
   "outputs": [],
   "source": [
    "from deepagri.data_full import get_df_full\n",
    "\n",
    "from tensorflow.keras import models,layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ef041e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:42:50.911829Z",
     "start_time": "2022-03-04T14:42:44.813457Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/constantintalandier/.pyenv/versions/3.8.12/envs/deepagri/lib/python3.8/site-packages/pandas/core/indexes/base.py:6982: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  return Index(sequences[0], name=names)\n"
     ]
    }
   ],
   "source": [
    "df=get_df_full(agg_type='S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "417ffd8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:42:51.348667Z",
     "start_time": "2022-03-04T14:42:51.309317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agriculteur</th>\n",
       "      <th>Production</th>\n",
       "      <th>RatioSep</th>\n",
       "      <th>RatioOct</th>\n",
       "      <th>Prix_matos</th>\n",
       "      <th>Surface_n-1</th>\n",
       "      <th>tmax_c jan-mar</th>\n",
       "      <th>tmax_c sept-jan_n-1</th>\n",
       "      <th>tmin_c jan-mar</th>\n",
       "      <th>tmin_c sept-jan_n-1</th>\n",
       "      <th>...</th>\n",
       "      <th>cloudcov_avg_pct jan-mar</th>\n",
       "      <th>cloudcov_avg_pct sept-jan_n-1</th>\n",
       "      <th>dewmax_c jan-mar</th>\n",
       "      <th>dewmax_c sept-jan_n-1</th>\n",
       "      <th>snow_mm jan-mar</th>\n",
       "      <th>snow_mm sept-jan_n-1</th>\n",
       "      <th>uv_idx jan-mar</th>\n",
       "      <th>uv_idx sept-jan_n-1</th>\n",
       "      <th>sunhour jan-mar</th>\n",
       "      <th>sunhour sept-jan_n-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-1</th>\n",
       "      <td>2820.041792</td>\n",
       "      <td>239640.3</td>\n",
       "      <td>1.229426</td>\n",
       "      <td>1.255319</td>\n",
       "      <td>92.741667</td>\n",
       "      <td>69.712601</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.052966</td>\n",
       "      <td>44.610656</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1.322034</td>\n",
       "      <td>2.991803</td>\n",
       "      <td>6.638983</td>\n",
       "      <td>8.230328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-2</th>\n",
       "      <td>3563.698886</td>\n",
       "      <td>1485134.7</td>\n",
       "      <td>1.229426</td>\n",
       "      <td>1.255319</td>\n",
       "      <td>92.741667</td>\n",
       "      <td>89.977942</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.419492</td>\n",
       "      <td>52.994877</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.525424</td>\n",
       "      <td>3.081967</td>\n",
       "      <td>6.220339</td>\n",
       "      <td>7.083607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-3</th>\n",
       "      <td>4276.654443</td>\n",
       "      <td>307450.0</td>\n",
       "      <td>1.229426</td>\n",
       "      <td>1.255319</td>\n",
       "      <td>92.741667</td>\n",
       "      <td>68.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57.911017</td>\n",
       "      <td>43.866803</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.559322</td>\n",
       "      <td>3.180328</td>\n",
       "      <td>6.772881</td>\n",
       "      <td>7.959836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-4</th>\n",
       "      <td>1462.803043</td>\n",
       "      <td>6233.7</td>\n",
       "      <td>1.229426</td>\n",
       "      <td>1.255319</td>\n",
       "      <td>92.741667</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>37.184322</td>\n",
       "      <td>26.763320</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>83.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.440678</td>\n",
       "      <td>3.065574</td>\n",
       "      <td>7.888136</td>\n",
       "      <td>9.043443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-5</th>\n",
       "      <td>1406.337173</td>\n",
       "      <td>9753.9</td>\n",
       "      <td>1.229426</td>\n",
       "      <td>1.255319</td>\n",
       "      <td>92.741667</td>\n",
       "      <td>41.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.108051</td>\n",
       "      <td>31.378074</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>131.3</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1.355932</td>\n",
       "      <td>2.483607</td>\n",
       "      <td>7.027119</td>\n",
       "      <td>8.846721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-91</th>\n",
       "      <td>422.282609</td>\n",
       "      <td>243243.0</td>\n",
       "      <td>1.104197</td>\n",
       "      <td>1.072703</td>\n",
       "      <td>89.891667</td>\n",
       "      <td>72.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.601695</td>\n",
       "      <td>56.861680</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.186441</td>\n",
       "      <td>3.549180</td>\n",
       "      <td>6.169492</td>\n",
       "      <td>6.913115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-93</th>\n",
       "      <td>80.734902</td>\n",
       "      <td>2739.0</td>\n",
       "      <td>1.104197</td>\n",
       "      <td>1.072703</td>\n",
       "      <td>89.891667</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.703390</td>\n",
       "      <td>34.394467</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.152542</td>\n",
       "      <td>4.368852</td>\n",
       "      <td>7.598305</td>\n",
       "      <td>8.335246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-94</th>\n",
       "      <td>65.237675</td>\n",
       "      <td>3483.0</td>\n",
       "      <td>1.104197</td>\n",
       "      <td>1.072703</td>\n",
       "      <td>89.891667</td>\n",
       "      <td>72.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.252119</td>\n",
       "      <td>58.018443</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.169492</td>\n",
       "      <td>3.606557</td>\n",
       "      <td>6.218644</td>\n",
       "      <td>6.842623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-95</th>\n",
       "      <td>213.709486</td>\n",
       "      <td>198121.0</td>\n",
       "      <td>1.104197</td>\n",
       "      <td>1.072703</td>\n",
       "      <td>89.891667</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.307203</td>\n",
       "      <td>60.451844</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.101695</td>\n",
       "      <td>3.393443</td>\n",
       "      <td>5.942373</td>\n",
       "      <td>6.540984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-20</th>\n",
       "      <td>1526.132188</td>\n",
       "      <td>297.5</td>\n",
       "      <td>1.104197</td>\n",
       "      <td>1.072703</td>\n",
       "      <td>89.891667</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.286017</td>\n",
       "      <td>40.868852</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.033898</td>\n",
       "      <td>4.196721</td>\n",
       "      <td>6.855932</td>\n",
       "      <td>7.786066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1116 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Agriculteur  Production  RatioSep  RatioOct  Prix_matos Surface_n-1  \\\n",
       "2010-1   2820.041792    239640.3  1.229426  1.255319   92.741667   69.712601   \n",
       "2010-2   3563.698886   1485134.7  1.229426  1.255319   92.741667   89.977942   \n",
       "2010-3   4276.654443    307450.0  1.229426  1.255319   92.741667        68.0   \n",
       "2010-4   1462.803043      6233.7  1.229426  1.255319   92.741667        35.0   \n",
       "2010-5   1406.337173      9753.9  1.229426  1.255319   92.741667        41.0   \n",
       "...              ...         ...       ...       ...         ...         ...   \n",
       "2021-91   422.282609    243243.0  1.104197  1.072703   89.891667        72.0   \n",
       "2021-93    80.734902      2739.0  1.104197  1.072703   89.891667        78.0   \n",
       "2021-94    65.237675      3483.0  1.104197  1.072703   89.891667        72.0   \n",
       "2021-95   213.709486    198121.0  1.104197  1.072703   89.891667        78.0   \n",
       "2021-20  1526.132188       297.5  1.104197  1.072703   89.891667        70.0   \n",
       "\n",
       "         tmax_c jan-mar  tmax_c sept-jan_n-1  tmin_c jan-mar  \\\n",
       "2010-1             10.0                 28.0             8.0   \n",
       "2010-2             10.0                 21.0            10.0   \n",
       "2010-3             10.0                 27.0            10.0   \n",
       "2010-4              8.0                 21.0             8.0   \n",
       "2010-5              8.0                 20.0             6.0   \n",
       "...                 ...                  ...             ...   \n",
       "2021-91             9.0                 19.0            11.0   \n",
       "2021-93            10.0                 48.0            24.0   \n",
       "2021-94             9.0                 19.0            11.0   \n",
       "2021-95             9.0                 19.0            11.0   \n",
       "2021-20            10.0                 24.0            14.0   \n",
       "\n",
       "         tmin_c sept-jan_n-1  ...  cloudcov_avg_pct jan-mar  \\\n",
       "2010-1                  18.0  ...                 59.052966   \n",
       "2010-2                  21.0  ...                 64.419492   \n",
       "2010-3                  16.0  ...                 57.911017   \n",
       "2010-4                  17.0  ...                 37.184322   \n",
       "2010-5                  18.0  ...                 48.108051   \n",
       "...                      ...  ...                       ...   \n",
       "2021-91                 15.0  ...                 63.601695   \n",
       "2021-93                 40.0  ...                 41.703390   \n",
       "2021-94                 17.0  ...                 64.252119   \n",
       "2021-95                 20.0  ...                 66.307203   \n",
       "2021-20                 15.0  ...                 49.286017   \n",
       "\n",
       "         cloudcov_avg_pct sept-jan_n-1  dewmax_c jan-mar  \\\n",
       "2010-1                       44.610656               8.0   \n",
       "2010-2                       52.994877              10.0   \n",
       "2010-3                       43.866803               9.0   \n",
       "2010-4                       26.763320               7.0   \n",
       "2010-5                       31.378074               7.0   \n",
       "...                                ...               ...   \n",
       "2021-91                      56.861680              12.0   \n",
       "2021-93                      34.394467              12.0   \n",
       "2021-94                      58.018443              12.0   \n",
       "2021-95                      60.451844              10.0   \n",
       "2021-20                      40.868852              12.0   \n",
       "\n",
       "         dewmax_c sept-jan_n-1  snow_mm jan-mar  snow_mm sept-jan_n-1  \\\n",
       "2010-1                    17.0             39.5                  16.6   \n",
       "2010-2                    18.0             18.7                   9.9   \n",
       "2010-3                    19.0             27.0                  15.2   \n",
       "2010-4                    18.0             83.5                   5.5   \n",
       "2010-5                    18.0            131.3                  18.7   \n",
       "...                        ...              ...                   ...   \n",
       "2021-91                   17.0              8.6                   3.5   \n",
       "2021-93                   20.0              0.0                   0.0   \n",
       "2021-94                   17.0             10.1                   4.7   \n",
       "2021-95                   17.0             11.1                   2.0   \n",
       "2021-20                   19.0              0.0                   0.0   \n",
       "\n",
       "         uv_idx jan-mar  uv_idx sept-jan_n-1  sunhour jan-mar  \\\n",
       "2010-1         1.322034             2.991803         6.638983   \n",
       "2010-2         1.525424             3.081967         6.220339   \n",
       "2010-3         1.559322             3.180328         6.772881   \n",
       "2010-4         1.440678             3.065574         7.888136   \n",
       "2010-5         1.355932             2.483607         7.027119   \n",
       "...                 ...                  ...              ...   \n",
       "2021-91        2.186441             3.549180         6.169492   \n",
       "2021-93        3.152542             4.368852         7.598305   \n",
       "2021-94        2.169492             3.606557         6.218644   \n",
       "2021-95        2.101695             3.393443         5.942373   \n",
       "2021-20        3.033898             4.196721         6.855932   \n",
       "\n",
       "         sunhour sept-jan_n-1  \n",
       "2010-1               8.230328  \n",
       "2010-2               7.083607  \n",
       "2010-3               7.959836  \n",
       "2010-4               9.043443  \n",
       "2010-5               8.846721  \n",
       "...                       ...  \n",
       "2021-91              6.913115  \n",
       "2021-93              8.335246  \n",
       "2021-94              6.842623  \n",
       "2021-95              6.540984  \n",
       "2021-20              7.786066  \n",
       "\n",
       "[1116 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b65064",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:42:51.769152Z",
     "start_time": "2022-03-04T14:42:51.743590Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test=df.iloc[-93:].drop(columns=['Production'])\n",
    "#X_test=df.iloc[-93:][['Surface_n-1','Agriculteur','windspeed_max sept-jan_n-1']]\n",
    "y_test=df.iloc[-93:]['Production']\n",
    "X_train=df.iloc[:-93].drop(columns=['Production'])\n",
    "#X_train=df.iloc[:-93][['Surface_n-1','Agriculteur','windspeed_max sept-jan_n-1']]\n",
    "y_train=df.iloc[:-93]['Production']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96058293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:42:52.339187Z",
     "start_time": "2022-03-04T14:42:52.316643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1116, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e1575b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:55:32.752349Z",
     "start_time": "2022-03-04T14:55:32.678937Z"
    }
   },
   "outputs": [],
   "source": [
    "#instensiation du model\n",
    "model=models.Sequential()\n",
    "#Création des layers\n",
    "model.add(layers.Dense(60,activation='relu',input_dim=27)) #Création d'une layer de 5 neurones avec une activation 'relu' et une dimension d'entrée de 2 params\n",
    "model.add(layers.Dense(30,activation='relu')) # Layer avec 10 neurones, pas besoin de input_dim \n",
    "model.add(layers.Dense(30,activation='relu')) # Layer avec 10 neurones, pas besoin de input_dim \n",
    "model.add(layers.Dense(20,activation='relu')) # Layer avec 10 neurones, pas besoin de input_dim \n",
    "model.add(layers.Dense(10,activation='relu')) # Layer avec 10 neurones, pas besoin de input_dim \n",
    "model.add(layers.Dense(1,activation='linear')) # Layer de sortie pour une classification (1 neurone, 'sigmoid')\n",
    "#Compilation du model avec les fonctions d'optimisation et de loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d80adff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:55:33.230521Z",
     "start_time": "2022-03-04T14:55:33.202894Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mae', # We've already mentioned this loss function in Logistic Regression\n",
    "                  optimizer='adam', # Optimizer in Deep Learning = solver in Machine Learning | Adam = our best friend\n",
    "                  metrics=['mae']) # Let's focus on the accuracy, our dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8dc9352c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:56:33.213857Z",
     "start_time": "2022-03-04T14:56:01.529582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148106.6562 - mae: 148106.6562 - val_loss: 142453.7031 - val_mae: 142453.7031\n",
      "Epoch 2/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148218.2031 - mae: 148218.2031 - val_loss: 139679.4375 - val_mae: 139679.4375\n",
      "Epoch 3/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147615.4219 - mae: 147615.4219 - val_loss: 141487.9844 - val_mae: 141487.9844\n",
      "Epoch 4/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148138.4531 - mae: 148138.4531 - val_loss: 139558.2969 - val_mae: 139558.2969\n",
      "Epoch 5/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148461.0938 - mae: 148461.0938 - val_loss: 138952.9219 - val_mae: 138952.9219\n",
      "Epoch 6/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148294.5625 - mae: 148294.5625 - val_loss: 139857.4062 - val_mae: 139857.4062\n",
      "Epoch 7/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147254.8125 - mae: 147254.8125 - val_loss: 140111.7344 - val_mae: 140111.7344\n",
      "Epoch 8/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148680.4375 - mae: 148680.4375 - val_loss: 140288.7969 - val_mae: 140288.7969\n",
      "Epoch 9/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147983.9844 - mae: 147983.9844 - val_loss: 139588.5469 - val_mae: 139588.5469\n",
      "Epoch 10/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147516.3438 - mae: 147516.3438 - val_loss: 140952.4844 - val_mae: 140952.4844\n",
      "Epoch 11/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148385.0312 - mae: 148385.0312 - val_loss: 139176.6406 - val_mae: 139176.6406\n",
      "Epoch 12/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147151.5469 - mae: 147151.5469 - val_loss: 142617.4688 - val_mae: 142617.4688\n",
      "Epoch 13/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148225.7500 - mae: 148225.7500 - val_loss: 139944.6094 - val_mae: 139944.6094\n",
      "Epoch 14/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147324.5469 - mae: 147324.5469 - val_loss: 139589.0469 - val_mae: 139589.0469\n",
      "Epoch 15/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146767.8438 - mae: 146767.8438 - val_loss: 143333.7031 - val_mae: 143333.7031\n",
      "Epoch 16/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149090.6875 - mae: 149090.6875 - val_loss: 139932.3906 - val_mae: 139932.3906\n",
      "Epoch 17/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147249.5469 - mae: 147249.5469 - val_loss: 140248.7188 - val_mae: 140248.7188\n",
      "Epoch 18/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146906.0156 - mae: 146906.0156 - val_loss: 140846.2500 - val_mae: 140846.2500\n",
      "Epoch 19/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147446.8125 - mae: 147446.8125 - val_loss: 141385.0469 - val_mae: 141385.0469\n",
      "Epoch 20/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147724.1094 - mae: 147724.1094 - val_loss: 138500.4688 - val_mae: 138500.4688\n",
      "Epoch 21/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148300.7656 - mae: 148300.7656 - val_loss: 140747.6406 - val_mae: 140747.6406\n",
      "Epoch 22/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148332.9688 - mae: 148332.9688 - val_loss: 145318.7344 - val_mae: 145318.7344\n",
      "Epoch 23/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 153297.4375 - mae: 153297.4375 - val_loss: 143560.7969 - val_mae: 143560.7969\n",
      "Epoch 24/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 150999.3594 - mae: 150999.3594 - val_loss: 140020.8125 - val_mae: 140020.8125\n",
      "Epoch 25/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148245.0156 - mae: 148245.0156 - val_loss: 137889.7031 - val_mae: 137889.7031\n",
      "Epoch 26/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 160412.6719 - mae: 160412.6719 - val_loss: 149607.3750 - val_mae: 149607.3750\n",
      "Epoch 27/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148314.7500 - mae: 148314.7500 - val_loss: 144394.9062 - val_mae: 144394.9062\n",
      "Epoch 28/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148656.2188 - mae: 148656.2188 - val_loss: 139909.6094 - val_mae: 139909.6094\n",
      "Epoch 29/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148147.1250 - mae: 148147.1250 - val_loss: 141079.9375 - val_mae: 141079.9375\n",
      "Epoch 30/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149793.4375 - mae: 149793.4375 - val_loss: 140054.8906 - val_mae: 140054.8906\n",
      "Epoch 31/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146840.1875 - mae: 146840.1875 - val_loss: 140637.5938 - val_mae: 140637.5938\n",
      "Epoch 32/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146784.5625 - mae: 146784.5625 - val_loss: 139975.8281 - val_mae: 139975.8281\n",
      "Epoch 33/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147659.2969 - mae: 147659.2969 - val_loss: 139054.0625 - val_mae: 139054.0625\n",
      "Epoch 34/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147811.2344 - mae: 147811.2344 - val_loss: 140527.0781 - val_mae: 140527.0781\n",
      "Epoch 35/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146708.2812 - mae: 146708.2812 - val_loss: 139742.6094 - val_mae: 139742.6094\n",
      "Epoch 36/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149074.1719 - mae: 149074.1719 - val_loss: 141958.8125 - val_mae: 141958.8125\n",
      "Epoch 37/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148219.5156 - mae: 148219.5156 - val_loss: 143206.5625 - val_mae: 143206.5625\n",
      "Epoch 38/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147553.2344 - mae: 147553.2344 - val_loss: 138413.9688 - val_mae: 138413.9688\n",
      "Epoch 39/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147679.1250 - mae: 147679.1250 - val_loss: 138371.7969 - val_mae: 138371.7969\n",
      "Epoch 40/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148865.0625 - mae: 148865.0625 - val_loss: 137839.3906 - val_mae: 137839.3906\n",
      "Epoch 41/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148840.5156 - mae: 148840.5156 - val_loss: 140882.9062 - val_mae: 140882.9062\n",
      "Epoch 42/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148823.9219 - mae: 148823.9219 - val_loss: 138706.9531 - val_mae: 138706.9531\n",
      "Epoch 43/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147268.5312 - mae: 147268.5312 - val_loss: 138608.6094 - val_mae: 138608.6094\n",
      "Epoch 44/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148446.4844 - mae: 148446.4844 - val_loss: 140240.3125 - val_mae: 140240.3125\n",
      "Epoch 45/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147008.5625 - mae: 147008.5625 - val_loss: 138057.7969 - val_mae: 138057.7969\n",
      "Epoch 46/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 150238.4375 - mae: 150238.4375 - val_loss: 143886.6875 - val_mae: 143886.6875\n",
      "Epoch 47/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 155053.7031 - mae: 155053.7031 - val_loss: 146609.0469 - val_mae: 146609.0469\n",
      "Epoch 48/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149524.3125 - mae: 149524.3125 - val_loss: 141125.7031 - val_mae: 141125.7031\n",
      "Epoch 49/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148337.7344 - mae: 148337.7344 - val_loss: 138660.0156 - val_mae: 138660.0156\n",
      "Epoch 50/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146893.2500 - mae: 146893.2500 - val_loss: 139797.8906 - val_mae: 139797.8906\n",
      "Epoch 51/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149255.6094 - mae: 149255.6094 - val_loss: 144618.2344 - val_mae: 144618.2344\n",
      "Epoch 52/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146728.0156 - mae: 146728.0156 - val_loss: 143049.9375 - val_mae: 143049.9375\n",
      "Epoch 53/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147350.5000 - mae: 147350.5000 - val_loss: 140377.4219 - val_mae: 140377.4219\n",
      "Epoch 54/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 147685.7188 - mae: 147685.7188 - val_loss: 138752.1562 - val_mae: 138752.1562\n",
      "Epoch 55/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148076.0156 - mae: 148076.0156 - val_loss: 139462.1562 - val_mae: 139462.1562\n",
      "Epoch 56/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147057.4219 - mae: 147057.4219 - val_loss: 139013.0156 - val_mae: 139013.0156\n",
      "Epoch 57/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149231.4375 - mae: 149231.4375 - val_loss: 142434.4531 - val_mae: 142434.4531\n",
      "Epoch 58/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148006.8906 - mae: 148006.8906 - val_loss: 140656.3281 - val_mae: 140656.3281\n",
      "Epoch 59/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 149913.1406 - mae: 149913.1406 - val_loss: 143040.1875 - val_mae: 143040.1875\n",
      "Epoch 60/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 147154.5781 - mae: 147154.5781 - val_loss: 143526.5625 - val_mae: 143526.5625\n",
      "Epoch 61/10000\n",
      "32/32 [==============================] - 0s 985us/step - loss: 149538.3906 - mae: 149538.3906 - val_loss: 141853.3906 - val_mae: 141853.3906\n",
      "Epoch 62/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149871.1250 - mae: 149871.1250 - val_loss: 141906.1250 - val_mae: 141906.1250\n",
      "Epoch 63/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 146288.3594 - mae: 146288.3594 - val_loss: 142111.3438 - val_mae: 142111.3438\n",
      "Epoch 64/10000\n",
      "32/32 [==============================] - 0s 989us/step - loss: 148332.5625 - mae: 148332.5625 - val_loss: 143645.7969 - val_mae: 143645.7969\n",
      "Epoch 65/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148045.2031 - mae: 148045.2031 - val_loss: 141747.5156 - val_mae: 141747.5156\n",
      "Epoch 66/10000\n",
      "32/32 [==============================] - 0s 983us/step - loss: 147642.4531 - mae: 147642.4531 - val_loss: 149365.2969 - val_mae: 149365.2969\n",
      "Epoch 67/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148869.4531 - mae: 148869.4531 - val_loss: 141741.2969 - val_mae: 141741.2969\n",
      "Epoch 68/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146864.5000 - mae: 146864.5000 - val_loss: 143419.6094 - val_mae: 143419.6094\n",
      "Epoch 69/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147922.9531 - mae: 147922.9531 - val_loss: 140366.4375 - val_mae: 140366.4375\n",
      "Epoch 70/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147823.7188 - mae: 147823.7188 - val_loss: 137741.0156 - val_mae: 137741.0156\n",
      "Epoch 71/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147932.8281 - mae: 147932.8281 - val_loss: 143379.2969 - val_mae: 143379.2969\n",
      "Epoch 72/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 146542.0312 - mae: 146542.0312 - val_loss: 141776.3906 - val_mae: 141776.3906\n",
      "Epoch 73/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146737.7812 - mae: 146737.7812 - val_loss: 139496.8438 - val_mae: 139496.8438\n",
      "Epoch 74/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146510.8125 - mae: 146510.8125 - val_loss: 140964.3594 - val_mae: 140964.3594\n",
      "Epoch 75/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 149839.7812 - mae: 149839.7812 - val_loss: 140000.0156 - val_mae: 140000.0156\n",
      "Epoch 76/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149933.4062 - mae: 149933.4062 - val_loss: 149055.8125 - val_mae: 149055.8125\n",
      "Epoch 77/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147892.8281 - mae: 147892.8281 - val_loss: 142137.4375 - val_mae: 142137.4375\n",
      "Epoch 78/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147541.5312 - mae: 147541.5312 - val_loss: 138325.5469 - val_mae: 138325.5469\n",
      "Epoch 79/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147699.7031 - mae: 147699.7031 - val_loss: 140562.0156 - val_mae: 140562.0156\n",
      "Epoch 80/10000\n",
      "32/32 [==============================] - 0s 996us/step - loss: 146060.7500 - mae: 146060.7500 - val_loss: 138242.0469 - val_mae: 138242.0469\n",
      "Epoch 81/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146813.4531 - mae: 146813.4531 - val_loss: 138584.7031 - val_mae: 138584.7031\n",
      "Epoch 82/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147916.0938 - mae: 147916.0938 - val_loss: 141779.9062 - val_mae: 141779.9062\n",
      "Epoch 83/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 148471.4531 - mae: 148471.4531 - val_loss: 141382.8594 - val_mae: 141382.8594\n",
      "Epoch 84/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 149709.9531 - mae: 149709.9531 - val_loss: 139408.6719 - val_mae: 139408.6719\n",
      "Epoch 85/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 152189.7031 - mae: 152189.7031 - val_loss: 139981.8906 - val_mae: 139981.8906\n",
      "Epoch 86/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145298.5469 - mae: 145298.5469 - val_loss: 143231.3438 - val_mae: 143231.3438\n",
      "Epoch 87/10000\n",
      "32/32 [==============================] - 0s 986us/step - loss: 149398.3906 - mae: 149398.3906 - val_loss: 142028.3594 - val_mae: 142028.3594\n",
      "Epoch 88/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 150483.0156 - mae: 150483.0156 - val_loss: 143468.8750 - val_mae: 143468.8750\n",
      "Epoch 89/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 147187.7812 - mae: 147187.7812 - val_loss: 138512.5000 - val_mae: 138512.5000\n",
      "Epoch 90/10000\n",
      "32/32 [==============================] - 0s 967us/step - loss: 147114.0156 - mae: 147114.0156 - val_loss: 145647.0156 - val_mae: 145647.0156\n",
      "Epoch 91/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146013.4375 - mae: 146013.4375 - val_loss: 143439.6406 - val_mae: 143439.6406\n",
      "Epoch 92/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146595.8125 - mae: 146595.8125 - val_loss: 138134.4688 - val_mae: 138134.4688\n",
      "Epoch 93/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145710.1094 - mae: 145710.1094 - val_loss: 138977.0156 - val_mae: 138977.0156\n",
      "Epoch 94/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146202.5781 - mae: 146202.5781 - val_loss: 139837.7031 - val_mae: 139837.7031\n",
      "Epoch 95/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147198.9375 - mae: 147198.9375 - val_loss: 140941.2812 - val_mae: 140941.2812\n",
      "Epoch 96/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 151834.4375 - mae: 151834.4375 - val_loss: 143356.4688 - val_mae: 143356.4688\n",
      "Epoch 97/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147335.3281 - mae: 147335.3281 - val_loss: 137573.2656 - val_mae: 137573.2656\n",
      "Epoch 98/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145868.1406 - mae: 145868.1406 - val_loss: 144002.1875 - val_mae: 144002.1875\n",
      "Epoch 99/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148309.3594 - mae: 148309.3594 - val_loss: 144544.6562 - val_mae: 144544.6562\n",
      "Epoch 100/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147303.8750 - mae: 147303.8750 - val_loss: 139985.8750 - val_mae: 139985.8750\n",
      "Epoch 101/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145702.0312 - mae: 145702.0312 - val_loss: 137257.2344 - val_mae: 137257.2344\n",
      "Epoch 102/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145748.9062 - mae: 145748.9062 - val_loss: 139469.1562 - val_mae: 139469.1562\n",
      "Epoch 103/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 150481.6250 - mae: 150481.6250 - val_loss: 141686.8438 - val_mae: 141686.8438\n",
      "Epoch 104/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 146847.6719 - mae: 146847.6719 - val_loss: 149234.6562 - val_mae: 149234.6562\n",
      "Epoch 105/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148334.1719 - mae: 148334.1719 - val_loss: 138597.8750 - val_mae: 138597.8750\n",
      "Epoch 106/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147019.5781 - mae: 147019.5781 - val_loss: 137063.7969 - val_mae: 137063.7969\n",
      "Epoch 107/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 145476.0469 - mae: 145476.0469 - val_loss: 137469.0938 - val_mae: 137469.0938\n",
      "Epoch 108/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147411.0000 - mae: 147411.0000 - val_loss: 140564.6250 - val_mae: 140564.6250\n",
      "Epoch 109/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 148208.0469 - mae: 148208.0469 - val_loss: 147206.6094 - val_mae: 147206.6094\n",
      "Epoch 110/10000\n",
      "32/32 [==============================] - 0s 984us/step - loss: 148097.8906 - mae: 148097.8906 - val_loss: 143110.9688 - val_mae: 143110.9688\n",
      "Epoch 111/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146954.6250 - mae: 146954.6250 - val_loss: 139085.3594 - val_mae: 139085.3594\n",
      "Epoch 112/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148074.7500 - mae: 148074.7500 - val_loss: 142198.8125 - val_mae: 142198.8125\n",
      "Epoch 113/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146475.3906 - mae: 146475.3906 - val_loss: 140911.8750 - val_mae: 140911.8750\n",
      "Epoch 114/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147004.2344 - mae: 147004.2344 - val_loss: 143945.9844 - val_mae: 143945.9844\n",
      "Epoch 115/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146295.0312 - mae: 146295.0312 - val_loss: 139332.3281 - val_mae: 139332.3281\n",
      "Epoch 116/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147332.7812 - mae: 147332.7812 - val_loss: 143356.0781 - val_mae: 143356.0781\n",
      "Epoch 117/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146923.9688 - mae: 146923.9688 - val_loss: 137641.6094 - val_mae: 137641.6094\n",
      "Epoch 118/10000\n",
      "32/32 [==============================] - 0s 980us/step - loss: 148851.0156 - mae: 148851.0156 - val_loss: 138774.1719 - val_mae: 138774.1719\n",
      "Epoch 119/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149317.4375 - mae: 149317.4375 - val_loss: 142928.6406 - val_mae: 142928.6406\n",
      "Epoch 120/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148343.9219 - mae: 148343.9219 - val_loss: 140602.5000 - val_mae: 140602.5000\n",
      "Epoch 121/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146366.0781 - mae: 146366.0781 - val_loss: 140685.3906 - val_mae: 140685.3906\n",
      "Epoch 122/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146510.0469 - mae: 146510.0469 - val_loss: 139014.5469 - val_mae: 139014.5469\n",
      "Epoch 123/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146012.0781 - mae: 146012.0781 - val_loss: 140127.7344 - val_mae: 140127.7344\n",
      "Epoch 124/10000\n",
      "32/32 [==============================] - 0s 986us/step - loss: 146044.7812 - mae: 146044.7812 - val_loss: 139405.5156 - val_mae: 139405.5156\n",
      "Epoch 125/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147765.8125 - mae: 147765.8125 - val_loss: 145883.7969 - val_mae: 145883.7969\n",
      "Epoch 126/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146093.7500 - mae: 146093.7500 - val_loss: 143899.0469 - val_mae: 143899.0469\n",
      "Epoch 127/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147540.8438 - mae: 147540.8438 - val_loss: 142491.0312 - val_mae: 142491.0312\n",
      "Epoch 128/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147345.2500 - mae: 147345.2500 - val_loss: 144373.5625 - val_mae: 144373.5625\n",
      "Epoch 129/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146088.7812 - mae: 146088.7812 - val_loss: 139459.9844 - val_mae: 139459.9844\n",
      "Epoch 130/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146234.1875 - mae: 146234.1875 - val_loss: 136105.2188 - val_mae: 136105.2188\n",
      "Epoch 131/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146245.5312 - mae: 146245.5312 - val_loss: 137302.7344 - val_mae: 137302.7344\n",
      "Epoch 132/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 146447.3594 - mae: 146447.3594 - val_loss: 139630.8750 - val_mae: 139630.8750\n",
      "Epoch 133/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148440.4688 - mae: 148440.4688 - val_loss: 148357.3281 - val_mae: 148357.3281\n",
      "Epoch 134/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 147039.0469 - mae: 147039.0469 - val_loss: 141177.3281 - val_mae: 141177.3281\n",
      "Epoch 135/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147006.8281 - mae: 147006.8281 - val_loss: 139628.3281 - val_mae: 139628.3281\n",
      "Epoch 136/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146471.6875 - mae: 146471.6875 - val_loss: 138977.9531 - val_mae: 138977.9531\n",
      "Epoch 137/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146666.6094 - mae: 146666.6094 - val_loss: 141377.5156 - val_mae: 141377.5156\n",
      "Epoch 138/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148216.9531 - mae: 148216.9531 - val_loss: 157168.0000 - val_mae: 157168.0000\n",
      "Epoch 139/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 151008.5469 - mae: 151008.5469 - val_loss: 141771.0625 - val_mae: 141771.0625\n",
      "Epoch 140/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147621.9375 - mae: 147621.9375 - val_loss: 143662.4688 - val_mae: 143662.4688\n",
      "Epoch 141/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148685.3438 - mae: 148685.3438 - val_loss: 141968.4375 - val_mae: 141968.4375\n",
      "Epoch 142/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146048.4688 - mae: 146048.4688 - val_loss: 140571.8750 - val_mae: 140571.8750\n",
      "Epoch 143/10000\n",
      "32/32 [==============================] - 0s 996us/step - loss: 148517.4531 - mae: 148517.4531 - val_loss: 151807.2344 - val_mae: 151807.2344\n",
      "Epoch 144/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148389.3125 - mae: 148389.3125 - val_loss: 144731.6406 - val_mae: 144731.6406\n",
      "Epoch 145/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147133.1719 - mae: 147133.1719 - val_loss: 140099.0000 - val_mae: 140099.0000\n",
      "Epoch 146/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147099.2031 - mae: 147099.2031 - val_loss: 142287.4688 - val_mae: 142287.4688\n",
      "Epoch 147/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146671.1250 - mae: 146671.1250 - val_loss: 139645.7188 - val_mae: 139645.7188\n",
      "Epoch 148/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147111.4531 - mae: 147111.4531 - val_loss: 141542.4688 - val_mae: 141542.4688\n",
      "Epoch 149/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145413.9688 - mae: 145413.9688 - val_loss: 142899.0625 - val_mae: 142899.0625\n",
      "Epoch 150/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147385.2969 - mae: 147385.2969 - val_loss: 137230.3594 - val_mae: 137230.3594\n",
      "Epoch 151/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144917.9531 - mae: 144917.9531 - val_loss: 142531.4688 - val_mae: 142531.4688\n",
      "Epoch 152/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146875.5938 - mae: 146875.5938 - val_loss: 139471.0938 - val_mae: 139471.0938\n",
      "Epoch 153/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 145828.3438 - mae: 145828.3438 - val_loss: 137343.5625 - val_mae: 137343.5625\n",
      "Epoch 154/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146000.8281 - mae: 146000.8281 - val_loss: 138345.8750 - val_mae: 138345.8750\n",
      "Epoch 155/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145563.8438 - mae: 145563.8438 - val_loss: 140458.3594 - val_mae: 140458.3594\n",
      "Epoch 156/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144787.5938 - mae: 144787.5938 - val_loss: 139789.6094 - val_mae: 139789.6094\n",
      "Epoch 157/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145398.9219 - mae: 145398.9219 - val_loss: 139570.5000 - val_mae: 139570.5000\n",
      "Epoch 158/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146183.4062 - mae: 146183.4062 - val_loss: 138472.5312 - val_mae: 138472.5312\n",
      "Epoch 159/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145831.2188 - mae: 145831.2188 - val_loss: 142116.9688 - val_mae: 142116.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146154.8438 - mae: 146154.8438 - val_loss: 139683.2500 - val_mae: 139683.2500\n",
      "Epoch 161/10000\n",
      "32/32 [==============================] - 0s 986us/step - loss: 148369.9219 - mae: 148369.9219 - val_loss: 137985.7500 - val_mae: 137985.7500\n",
      "Epoch 162/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 145494.0000 - mae: 145494.0000 - val_loss: 138525.0156 - val_mae: 138525.0156\n",
      "Epoch 163/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145438.0156 - mae: 145438.0156 - val_loss: 136954.2500 - val_mae: 136954.2500\n",
      "Epoch 164/10000\n",
      "32/32 [==============================] - 0s 974us/step - loss: 147389.6562 - mae: 147389.6562 - val_loss: 140713.9688 - val_mae: 140713.9688\n",
      "Epoch 165/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145741.7031 - mae: 145741.7031 - val_loss: 138137.1719 - val_mae: 138137.1719\n",
      "Epoch 166/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145864.7344 - mae: 145864.7344 - val_loss: 139069.7500 - val_mae: 139069.7500\n",
      "Epoch 167/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145172.0781 - mae: 145172.0781 - val_loss: 154330.2500 - val_mae: 154330.2500\n",
      "Epoch 168/10000\n",
      "32/32 [==============================] - 0s 972us/step - loss: 147547.8125 - mae: 147547.8125 - val_loss: 144123.2969 - val_mae: 144123.2969\n",
      "Epoch 169/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 152005.2500 - mae: 152005.2500 - val_loss: 147600.4375 - val_mae: 147600.4375\n",
      "Epoch 170/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 150468.5312 - mae: 150468.5312 - val_loss: 142904.8750 - val_mae: 142904.8750\n",
      "Epoch 171/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148923.7188 - mae: 148923.7188 - val_loss: 141771.9844 - val_mae: 141771.9844\n",
      "Epoch 172/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147079.6094 - mae: 147079.6094 - val_loss: 144083.1250 - val_mae: 144083.1250\n",
      "Epoch 173/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148047.0625 - mae: 148047.0625 - val_loss: 142464.5625 - val_mae: 142464.5625\n",
      "Epoch 174/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149669.7031 - mae: 149669.7031 - val_loss: 147991.7969 - val_mae: 147991.7969\n",
      "Epoch 175/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148319.3438 - mae: 148319.3438 - val_loss: 139621.5781 - val_mae: 139621.5781\n",
      "Epoch 176/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146679.9688 - mae: 146679.9688 - val_loss: 140335.2812 - val_mae: 140335.2812\n",
      "Epoch 177/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145829.7812 - mae: 145829.7812 - val_loss: 139839.8906 - val_mae: 139839.8906\n",
      "Epoch 178/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145359.8906 - mae: 145359.8906 - val_loss: 144735.8594 - val_mae: 144735.8594\n",
      "Epoch 179/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145555.1875 - mae: 145555.1875 - val_loss: 140511.5312 - val_mae: 140511.5312\n",
      "Epoch 180/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145327.0000 - mae: 145327.0000 - val_loss: 138560.8281 - val_mae: 138560.8281\n",
      "Epoch 181/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146467.6094 - mae: 146467.6094 - val_loss: 147441.9219 - val_mae: 147441.9219\n",
      "Epoch 182/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 144789.2656 - mae: 144789.2656 - val_loss: 141254.8750 - val_mae: 141254.8750\n",
      "Epoch 183/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145523.1719 - mae: 145523.1719 - val_loss: 140123.4688 - val_mae: 140123.4688\n",
      "Epoch 184/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147600.9688 - mae: 147600.9688 - val_loss: 142952.8125 - val_mae: 142952.8125\n",
      "Epoch 185/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146539.5156 - mae: 146539.5156 - val_loss: 138693.0156 - val_mae: 138693.0156\n",
      "Epoch 186/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145982.2969 - mae: 145982.2969 - val_loss: 152992.5000 - val_mae: 152992.5000\n",
      "Epoch 187/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145681.2812 - mae: 145681.2812 - val_loss: 140598.9688 - val_mae: 140598.9688\n",
      "Epoch 188/10000\n",
      "32/32 [==============================] - 0s 995us/step - loss: 145838.3594 - mae: 145838.3594 - val_loss: 143554.4531 - val_mae: 143554.4531\n",
      "Epoch 189/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 148532.4062 - mae: 148532.4062 - val_loss: 140173.0938 - val_mae: 140173.0938\n",
      "Epoch 190/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146781.2656 - mae: 146781.2656 - val_loss: 139501.0781 - val_mae: 139501.0781\n",
      "Epoch 191/10000\n",
      "32/32 [==============================] - 0s 992us/step - loss: 147057.5469 - mae: 147057.5469 - val_loss: 139932.6094 - val_mae: 139932.6094\n",
      "Epoch 192/10000\n",
      "32/32 [==============================] - 0s 976us/step - loss: 144776.7188 - mae: 144776.7188 - val_loss: 138701.7812 - val_mae: 138701.7812\n",
      "Epoch 193/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144645.0781 - mae: 144645.0781 - val_loss: 140161.0469 - val_mae: 140161.0469\n",
      "Epoch 194/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148600.6406 - mae: 148600.6406 - val_loss: 142669.2188 - val_mae: 142669.2188\n",
      "Epoch 195/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 145581.2656 - mae: 145581.2656 - val_loss: 144043.7031 - val_mae: 144043.7031\n",
      "Epoch 196/10000\n",
      "32/32 [==============================] - 0s 964us/step - loss: 147063.1406 - mae: 147063.1406 - val_loss: 144693.0469 - val_mae: 144693.0469\n",
      "Epoch 197/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145559.7969 - mae: 145559.7969 - val_loss: 139687.9531 - val_mae: 139687.9531\n",
      "Epoch 198/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144350.7969 - mae: 144350.7969 - val_loss: 138502.0156 - val_mae: 138502.0156\n",
      "Epoch 199/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 144752.9219 - mae: 144752.9219 - val_loss: 137467.1875 - val_mae: 137467.1875\n",
      "Epoch 200/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145686.9688 - mae: 145686.9688 - val_loss: 138647.7031 - val_mae: 138647.7031\n",
      "Epoch 201/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145667.7500 - mae: 145667.7500 - val_loss: 138930.3594 - val_mae: 138930.3594\n",
      "Epoch 202/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145421.3438 - mae: 145421.3438 - val_loss: 140286.5781 - val_mae: 140286.5781\n",
      "Epoch 203/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146234.3125 - mae: 146234.3125 - val_loss: 140117.5469 - val_mae: 140117.5469\n",
      "Epoch 204/10000\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 144798.6406 - mae: 144798.6406 - val_loss: 142448.8281 - val_mae: 142448.8281\n",
      "Epoch 205/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144709.5469 - mae: 144709.5469 - val_loss: 140063.9688 - val_mae: 140063.9688\n",
      "Epoch 206/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146509.1875 - mae: 146509.1875 - val_loss: 142755.4844 - val_mae: 142755.4844\n",
      "Epoch 207/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147958.3906 - mae: 147958.3906 - val_loss: 143072.7656 - val_mae: 143072.7656\n",
      "Epoch 208/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147136.5469 - mae: 147136.5469 - val_loss: 138865.3281 - val_mae: 138865.3281\n",
      "Epoch 209/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146453.7031 - mae: 146453.7031 - val_loss: 136017.3281 - val_mae: 136017.3281\n",
      "Epoch 210/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144641.3750 - mae: 144641.3750 - val_loss: 144763.7344 - val_mae: 144763.7344\n",
      "Epoch 211/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145212.6719 - mae: 145212.6719 - val_loss: 140264.0000 - val_mae: 140264.0000\n",
      "Epoch 212/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 146701.4375 - mae: 146701.4375 - val_loss: 140632.7344 - val_mae: 140632.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146604.9062 - mae: 146604.9062 - val_loss: 143427.5312 - val_mae: 143427.5312\n",
      "Epoch 214/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144546.8750 - mae: 144546.8750 - val_loss: 140292.5312 - val_mae: 140292.5312\n",
      "Epoch 215/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146256.2656 - mae: 146256.2656 - val_loss: 148929.1250 - val_mae: 148929.1250\n",
      "Epoch 216/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144227.4688 - mae: 144227.4688 - val_loss: 141882.0625 - val_mae: 141882.0625\n",
      "Epoch 217/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146035.5781 - mae: 146035.5781 - val_loss: 139821.8125 - val_mae: 139821.8125\n",
      "Epoch 218/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144921.7500 - mae: 144921.7500 - val_loss: 145012.6719 - val_mae: 145012.6719\n",
      "Epoch 219/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145389.4688 - mae: 145389.4688 - val_loss: 139896.3594 - val_mae: 139896.3594\n",
      "Epoch 220/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149909.6875 - mae: 149909.6875 - val_loss: 140369.7500 - val_mae: 140369.7500\n",
      "Epoch 221/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 144228.4375 - mae: 144228.4375 - val_loss: 142060.9219 - val_mae: 142060.9219\n",
      "Epoch 222/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146137.0312 - mae: 146137.0312 - val_loss: 140115.4062 - val_mae: 140115.4062\n",
      "Epoch 223/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 145071.1250 - mae: 145071.1250 - val_loss: 139072.1406 - val_mae: 139072.1406\n",
      "Epoch 224/10000\n",
      "32/32 [==============================] - 0s 965us/step - loss: 149816.1406 - mae: 149816.1406 - val_loss: 137286.0156 - val_mae: 137286.0156\n",
      "Epoch 225/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146165.9531 - mae: 146165.9531 - val_loss: 140450.0625 - val_mae: 140450.0625\n",
      "Epoch 226/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143936.0156 - mae: 143936.0156 - val_loss: 138405.6406 - val_mae: 138405.6406\n",
      "Epoch 227/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144917.2188 - mae: 144917.2188 - val_loss: 140055.2969 - val_mae: 140055.2969\n",
      "Epoch 228/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144333.8125 - mae: 144333.8125 - val_loss: 142477.9844 - val_mae: 142477.9844\n",
      "Epoch 229/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144727.3906 - mae: 144727.3906 - val_loss: 141711.6719 - val_mae: 141711.6719\n",
      "Epoch 230/10000\n",
      "32/32 [==============================] - 0s 979us/step - loss: 145089.7812 - mae: 145089.7812 - val_loss: 140372.2656 - val_mae: 140372.2656\n",
      "Epoch 231/10000\n",
      "32/32 [==============================] - 0s 972us/step - loss: 145391.2812 - mae: 145391.2812 - val_loss: 137981.3594 - val_mae: 137981.3594\n",
      "Epoch 232/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143991.6250 - mae: 143991.6250 - val_loss: 138575.0938 - val_mae: 138575.0938\n",
      "Epoch 233/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144004.5312 - mae: 144004.5312 - val_loss: 143182.1250 - val_mae: 143182.1250\n",
      "Epoch 234/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145458.5156 - mae: 145458.5156 - val_loss: 138501.5625 - val_mae: 138501.5625\n",
      "Epoch 235/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144461.4531 - mae: 144461.4531 - val_loss: 142385.9844 - val_mae: 142385.9844\n",
      "Epoch 236/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146051.5938 - mae: 146051.5938 - val_loss: 146244.7500 - val_mae: 146244.7500\n",
      "Epoch 237/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144755.9688 - mae: 144755.9688 - val_loss: 143419.5312 - val_mae: 143419.5312\n",
      "Epoch 238/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148775.9062 - mae: 148775.9062 - val_loss: 137436.1250 - val_mae: 137436.1250\n",
      "Epoch 239/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144292.5938 - mae: 144292.5938 - val_loss: 155494.9844 - val_mae: 155494.9844\n",
      "Epoch 240/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149979.5156 - mae: 149979.5156 - val_loss: 141716.7812 - val_mae: 141716.7812\n",
      "Epoch 241/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144010.9844 - mae: 144010.9844 - val_loss: 144571.7031 - val_mae: 144571.7031\n",
      "Epoch 242/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148411.5156 - mae: 148411.5156 - val_loss: 140403.5000 - val_mae: 140403.5000\n",
      "Epoch 243/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144512.6562 - mae: 144512.6562 - val_loss: 142844.8125 - val_mae: 142844.8125\n",
      "Epoch 244/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144635.3750 - mae: 144635.3750 - val_loss: 140231.3906 - val_mae: 140231.3906\n",
      "Epoch 245/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143892.6562 - mae: 143892.6562 - val_loss: 141327.1562 - val_mae: 141327.1562\n",
      "Epoch 246/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 146519.3438 - mae: 146519.3438 - val_loss: 143045.6562 - val_mae: 143045.6562\n",
      "Epoch 247/10000\n",
      "32/32 [==============================] - 0s 986us/step - loss: 143839.0938 - mae: 143839.0938 - val_loss: 143177.8906 - val_mae: 143177.8906\n",
      "Epoch 248/10000\n",
      "32/32 [==============================] - 0s 989us/step - loss: 146531.1250 - mae: 146531.1250 - val_loss: 139665.9531 - val_mae: 139665.9531\n",
      "Epoch 249/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 142661.2188 - mae: 142661.2188 - val_loss: 145819.9531 - val_mae: 145819.9531\n",
      "Epoch 250/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145647.5156 - mae: 145647.5156 - val_loss: 140370.7031 - val_mae: 140370.7031\n",
      "Epoch 251/10000\n",
      "32/32 [==============================] - 0s 978us/step - loss: 143736.9844 - mae: 143736.9844 - val_loss: 141093.3594 - val_mae: 141093.3594\n",
      "Epoch 252/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 144704.2812 - mae: 144704.2812 - val_loss: 141843.1250 - val_mae: 141843.1250\n",
      "Epoch 253/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 144203.5938 - mae: 144203.5938 - val_loss: 138799.5312 - val_mae: 138799.5312\n",
      "Epoch 254/10000\n",
      "32/32 [==============================] - 0s 978us/step - loss: 144144.4375 - mae: 144144.4375 - val_loss: 139331.5312 - val_mae: 139331.5312\n",
      "Epoch 255/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143652.8438 - mae: 143652.8438 - val_loss: 142906.3281 - val_mae: 142906.3281\n",
      "Epoch 256/10000\n",
      "32/32 [==============================] - 0s 982us/step - loss: 145962.4844 - mae: 145962.4844 - val_loss: 141836.3594 - val_mae: 141836.3594\n",
      "Epoch 257/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144575.6406 - mae: 144575.6406 - val_loss: 138683.8125 - val_mae: 138683.8125\n",
      "Epoch 258/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144991.1406 - mae: 144991.1406 - val_loss: 137999.3594 - val_mae: 137999.3594\n",
      "Epoch 259/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146608.9531 - mae: 146608.9531 - val_loss: 145813.8750 - val_mae: 145813.8750\n",
      "Epoch 260/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143484.7031 - mae: 143484.7031 - val_loss: 138039.5156 - val_mae: 138039.5156\n",
      "Epoch 261/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144633.7500 - mae: 144633.7500 - val_loss: 137830.8125 - val_mae: 137830.8125\n",
      "Epoch 262/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144782.5000 - mae: 144782.5000 - val_loss: 141138.2188 - val_mae: 141138.2188\n",
      "Epoch 263/10000\n",
      "32/32 [==============================] - 0s 980us/step - loss: 144196.9062 - mae: 144196.9062 - val_loss: 138124.4375 - val_mae: 138124.4375\n",
      "Epoch 264/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143350.0781 - mae: 143350.0781 - val_loss: 140207.3594 - val_mae: 140207.3594\n",
      "Epoch 265/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 146713.4844 - mae: 146713.4844 - val_loss: 141909.0469 - val_mae: 141909.0469\n",
      "Epoch 266/10000\n",
      "32/32 [==============================] - 0s 989us/step - loss: 144335.6406 - mae: 144335.6406 - val_loss: 140162.5312 - val_mae: 140162.5312\n",
      "Epoch 267/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 143582.2812 - mae: 143582.2812 - val_loss: 140956.7812 - val_mae: 140956.7812\n",
      "Epoch 268/10000\n",
      "32/32 [==============================] - 0s 978us/step - loss: 144144.7031 - mae: 144144.7031 - val_loss: 138323.3281 - val_mae: 138323.3281\n",
      "Epoch 269/10000\n",
      "32/32 [==============================] - 0s 987us/step - loss: 144715.3125 - mae: 144715.3125 - val_loss: 139843.2969 - val_mae: 139843.2969\n",
      "Epoch 270/10000\n",
      "32/32 [==============================] - 0s 986us/step - loss: 146409.1406 - mae: 146409.1406 - val_loss: 137865.4375 - val_mae: 137865.4375\n",
      "Epoch 271/10000\n",
      "32/32 [==============================] - 0s 985us/step - loss: 144269.3438 - mae: 144269.3438 - val_loss: 139285.1094 - val_mae: 139285.1094\n",
      "Epoch 272/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 144636.6562 - mae: 144636.6562 - val_loss: 139248.9531 - val_mae: 139248.9531\n",
      "Epoch 273/10000\n",
      "32/32 [==============================] - 0s 965us/step - loss: 145737.5469 - mae: 145737.5469 - val_loss: 139520.2969 - val_mae: 139520.2969\n",
      "Epoch 274/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143926.6562 - mae: 143926.6562 - val_loss: 139108.6406 - val_mae: 139108.6406\n",
      "Epoch 275/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 144676.5469 - mae: 144676.5469 - val_loss: 140281.0469 - val_mae: 140281.0469\n",
      "Epoch 276/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144366.8438 - mae: 144366.8438 - val_loss: 140284.7344 - val_mae: 140284.7344\n",
      "Epoch 277/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 143049.8906 - mae: 143049.8906 - val_loss: 140269.0469 - val_mae: 140269.0469\n",
      "Epoch 278/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143308.4062 - mae: 143308.4062 - val_loss: 139758.4375 - val_mae: 139758.4375\n",
      "Epoch 279/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144069.9375 - mae: 144069.9375 - val_loss: 146309.2031 - val_mae: 146309.2031\n",
      "Epoch 280/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 147566.8125 - mae: 147566.8125 - val_loss: 144691.5000 - val_mae: 144691.5000\n",
      "Epoch 281/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145097.7188 - mae: 145097.7188 - val_loss: 145449.6094 - val_mae: 145449.6094\n",
      "Epoch 282/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143311.1562 - mae: 143311.1562 - val_loss: 141260.7344 - val_mae: 141260.7344\n",
      "Epoch 283/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145326.0938 - mae: 145326.0938 - val_loss: 139378.1406 - val_mae: 139378.1406\n",
      "Epoch 284/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146436.6562 - mae: 146436.6562 - val_loss: 138962.9688 - val_mae: 138962.9688\n",
      "Epoch 285/10000\n",
      "32/32 [==============================] - 0s 982us/step - loss: 145219.5625 - mae: 145219.5625 - val_loss: 141114.9844 - val_mae: 141114.9844\n",
      "Epoch 286/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 144840.9531 - mae: 144840.9531 - val_loss: 138139.2812 - val_mae: 138139.2812\n",
      "Epoch 287/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146085.3594 - mae: 146085.3594 - val_loss: 139203.2188 - val_mae: 139203.2188\n",
      "Epoch 288/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144116.8594 - mae: 144116.8594 - val_loss: 140490.5156 - val_mae: 140490.5156\n",
      "Epoch 289/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146450.8594 - mae: 146450.8594 - val_loss: 137700.7344 - val_mae: 137700.7344\n",
      "Epoch 290/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143997.5625 - mae: 143997.5625 - val_loss: 139088.8750 - val_mae: 139088.8750\n",
      "Epoch 291/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144535.6875 - mae: 144535.6875 - val_loss: 141749.9062 - val_mae: 141749.9062\n",
      "Epoch 292/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146572.0469 - mae: 146572.0469 - val_loss: 141269.6094 - val_mae: 141269.6094\n",
      "Epoch 293/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143934.0625 - mae: 143934.0625 - val_loss: 137263.0156 - val_mae: 137263.0156\n",
      "Epoch 294/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145971.8594 - mae: 145971.8594 - val_loss: 141761.7031 - val_mae: 141761.7031\n",
      "Epoch 295/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146531.9219 - mae: 146531.9219 - val_loss: 142642.9844 - val_mae: 142642.9844\n",
      "Epoch 296/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 145309.8438 - mae: 145309.8438 - val_loss: 154918.4531 - val_mae: 154918.4531\n",
      "Epoch 297/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144368.2656 - mae: 144368.2656 - val_loss: 145859.2344 - val_mae: 145859.2344\n",
      "Epoch 298/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142915.4219 - mae: 142915.4219 - val_loss: 139690.5000 - val_mae: 139690.5000\n",
      "Epoch 299/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145400.4062 - mae: 145400.4062 - val_loss: 152553.3125 - val_mae: 152553.3125\n",
      "Epoch 300/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145397.2812 - mae: 145397.2812 - val_loss: 145354.6719 - val_mae: 145354.6719\n",
      "Epoch 301/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145786.0781 - mae: 145786.0781 - val_loss: 143143.6094 - val_mae: 143143.6094\n",
      "Epoch 302/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 145731.8750 - mae: 145731.8750 - val_loss: 146623.4219 - val_mae: 146623.4219\n",
      "Epoch 303/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145293.3906 - mae: 145293.3906 - val_loss: 141221.3906 - val_mae: 141221.3906\n",
      "Epoch 304/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145433.3750 - mae: 145433.3750 - val_loss: 146306.6094 - val_mae: 146306.6094\n",
      "Epoch 305/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143665.2344 - mae: 143665.2344 - val_loss: 141364.2188 - val_mae: 141364.2188\n",
      "Epoch 306/10000\n",
      "32/32 [==============================] - 0s 992us/step - loss: 144685.4375 - mae: 144685.4375 - val_loss: 139386.7656 - val_mae: 139386.7656\n",
      "Epoch 307/10000\n",
      "32/32 [==============================] - 0s 979us/step - loss: 145024.2344 - mae: 145024.2344 - val_loss: 141548.5000 - val_mae: 141548.5000\n",
      "Epoch 308/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143173.9062 - mae: 143173.9062 - val_loss: 142959.0312 - val_mae: 142959.0312\n",
      "Epoch 309/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143896.4062 - mae: 143896.4062 - val_loss: 140906.5000 - val_mae: 140906.5000\n",
      "Epoch 310/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142602.9219 - mae: 142602.9219 - val_loss: 142195.7969 - val_mae: 142195.7969\n",
      "Epoch 311/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143827.0000 - mae: 143827.0000 - val_loss: 140076.4219 - val_mae: 140076.4219\n",
      "Epoch 312/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 144145.4531 - mae: 144145.4531 - val_loss: 141912.8281 - val_mae: 141912.8281\n",
      "Epoch 313/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144383.7031 - mae: 144383.7031 - val_loss: 149339.7031 - val_mae: 149339.7031\n",
      "Epoch 314/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146868.7812 - mae: 146868.7812 - val_loss: 142599.9844 - val_mae: 142599.9844\n",
      "Epoch 315/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 144196.1562 - mae: 144196.1562 - val_loss: 138961.1562 - val_mae: 138961.1562\n",
      "Epoch 316/10000\n",
      "32/32 [==============================] - 0s 983us/step - loss: 143247.1094 - mae: 143247.1094 - val_loss: 142006.2188 - val_mae: 142006.2188\n",
      "Epoch 317/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143485.4219 - mae: 143485.4219 - val_loss: 140758.3125 - val_mae: 140758.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 147261.2031 - mae: 147261.2031 - val_loss: 149077.1250 - val_mae: 149077.1250\n",
      "Epoch 319/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145235.2812 - mae: 145235.2812 - val_loss: 139794.0469 - val_mae: 139794.0469\n",
      "Epoch 320/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143322.0156 - mae: 143322.0156 - val_loss: 140771.1250 - val_mae: 140771.1250\n",
      "Epoch 321/10000\n",
      "32/32 [==============================] - 0s 987us/step - loss: 144702.5938 - mae: 144702.5938 - val_loss: 140607.3906 - val_mae: 140607.3906\n",
      "Epoch 322/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 146836.9219 - mae: 146836.9219 - val_loss: 144065.4375 - val_mae: 144065.4375\n",
      "Epoch 323/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 149516.3594 - mae: 149516.3594 - val_loss: 144727.0469 - val_mae: 144727.0469\n",
      "Epoch 324/10000\n",
      "32/32 [==============================] - 0s 995us/step - loss: 147819.5469 - mae: 147819.5469 - val_loss: 140549.0000 - val_mae: 140549.0000\n",
      "Epoch 325/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146168.5625 - mae: 146168.5625 - val_loss: 138336.5625 - val_mae: 138336.5625\n",
      "Epoch 326/10000\n",
      "32/32 [==============================] - 0s 975us/step - loss: 146596.7656 - mae: 146596.7656 - val_loss: 144140.3906 - val_mae: 144140.3906\n",
      "Epoch 327/10000\n",
      "32/32 [==============================] - 0s 977us/step - loss: 143757.1875 - mae: 143757.1875 - val_loss: 139183.7500 - val_mae: 139183.7500\n",
      "Epoch 328/10000\n",
      "32/32 [==============================] - 0s 987us/step - loss: 142732.4219 - mae: 142732.4219 - val_loss: 143386.8750 - val_mae: 143386.8750\n",
      "Epoch 329/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 144175.9531 - mae: 144175.9531 - val_loss: 149129.7188 - val_mae: 149129.7188\n",
      "Epoch 330/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143352.9219 - mae: 143352.9219 - val_loss: 143408.5000 - val_mae: 143408.5000\n",
      "Epoch 331/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142651.9062 - mae: 142651.9062 - val_loss: 144955.1562 - val_mae: 144955.1562\n",
      "Epoch 332/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 144123.1562 - mae: 144123.1562 - val_loss: 138510.0938 - val_mae: 138510.0938\n",
      "Epoch 333/10000\n",
      "32/32 [==============================] - 0s 974us/step - loss: 143112.5625 - mae: 143112.5625 - val_loss: 137778.3594 - val_mae: 137778.3594\n",
      "Epoch 334/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143869.5312 - mae: 143869.5312 - val_loss: 139572.7031 - val_mae: 139572.7031\n",
      "Epoch 335/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143347.6094 - mae: 143347.6094 - val_loss: 136959.6406 - val_mae: 136959.6406\n",
      "Epoch 336/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142944.8750 - mae: 142944.8750 - val_loss: 137371.8750 - val_mae: 137371.8750\n",
      "Epoch 337/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143753.8125 - mae: 143753.8125 - val_loss: 140322.5469 - val_mae: 140322.5469\n",
      "Epoch 338/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 143430.0781 - mae: 143430.0781 - val_loss: 140445.0938 - val_mae: 140445.0938\n",
      "Epoch 339/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 148652.6406 - mae: 148652.6406 - val_loss: 145297.5312 - val_mae: 145297.5312\n",
      "Epoch 340/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146013.0000 - mae: 146013.0000 - val_loss: 144788.2969 - val_mae: 144788.2969\n",
      "Epoch 341/10000\n",
      "32/32 [==============================] - 0s 978us/step - loss: 145863.9844 - mae: 145863.9844 - val_loss: 140280.3594 - val_mae: 140280.3594\n",
      "Epoch 342/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143881.2344 - mae: 143881.2344 - val_loss: 137567.5625 - val_mae: 137567.5625\n",
      "Epoch 343/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143415.6719 - mae: 143415.6719 - val_loss: 139024.1406 - val_mae: 139024.1406\n",
      "Epoch 344/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142800.2812 - mae: 142800.2812 - val_loss: 140023.1250 - val_mae: 140023.1250\n",
      "Epoch 345/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143817.6719 - mae: 143817.6719 - val_loss: 143416.2969 - val_mae: 143416.2969\n",
      "Epoch 346/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 147210.2500 - mae: 147210.2500 - val_loss: 141861.1406 - val_mae: 141861.1406\n",
      "Epoch 347/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144000.2656 - mae: 144000.2656 - val_loss: 140645.5625 - val_mae: 140645.5625\n",
      "Epoch 348/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143529.2188 - mae: 143529.2188 - val_loss: 140007.9062 - val_mae: 140007.9062\n",
      "Epoch 349/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142025.5156 - mae: 142025.5156 - val_loss: 139469.8906 - val_mae: 139469.8906\n",
      "Epoch 350/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142927.1719 - mae: 142927.1719 - val_loss: 142112.5312 - val_mae: 142112.5312\n",
      "Epoch 351/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142648.8281 - mae: 142648.8281 - val_loss: 141655.1094 - val_mae: 141655.1094\n",
      "Epoch 352/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146962.1094 - mae: 146962.1094 - val_loss: 143742.3906 - val_mae: 143742.3906\n",
      "Epoch 353/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144283.3906 - mae: 144283.3906 - val_loss: 140503.3125 - val_mae: 140503.3125\n",
      "Epoch 354/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142938.1250 - mae: 142938.1250 - val_loss: 142988.0312 - val_mae: 142988.0312\n",
      "Epoch 355/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144806.7656 - mae: 144806.7656 - val_loss: 147449.0938 - val_mae: 147449.0938\n",
      "Epoch 356/10000\n",
      "32/32 [==============================] - 0s 996us/step - loss: 144840.2656 - mae: 144840.2656 - val_loss: 140918.1562 - val_mae: 140918.1562\n",
      "Epoch 357/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144692.5312 - mae: 144692.5312 - val_loss: 136693.1406 - val_mae: 136693.1406\n",
      "Epoch 358/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142807.5156 - mae: 142807.5156 - val_loss: 139726.2500 - val_mae: 139726.2500\n",
      "Epoch 359/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144279.1250 - mae: 144279.1250 - val_loss: 140758.5000 - val_mae: 140758.5000\n",
      "Epoch 360/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 143447.9531 - mae: 143447.9531 - val_loss: 139698.6562 - val_mae: 139698.6562\n",
      "Epoch 361/10000\n",
      "32/32 [==============================] - 0s 980us/step - loss: 142677.9062 - mae: 142677.9062 - val_loss: 139084.3594 - val_mae: 139084.3594\n",
      "Epoch 362/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142261.5156 - mae: 142261.5156 - val_loss: 140084.1875 - val_mae: 140084.1875\n",
      "Epoch 363/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143696.8281 - mae: 143696.8281 - val_loss: 139833.7812 - val_mae: 139833.7812\n",
      "Epoch 364/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144593.3750 - mae: 144593.3750 - val_loss: 137511.6719 - val_mae: 137511.6719\n",
      "Epoch 365/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147819.8750 - mae: 147819.8750 - val_loss: 143101.5625 - val_mae: 143101.5625\n",
      "Epoch 366/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142052.2344 - mae: 142052.2344 - val_loss: 141274.0156 - val_mae: 141274.0156\n",
      "Epoch 367/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 143948.4375 - mae: 143948.4375 - val_loss: 141451.3594 - val_mae: 141451.3594\n",
      "Epoch 368/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143703.9531 - mae: 143703.9531 - val_loss: 141358.7500 - val_mae: 141358.7500\n",
      "Epoch 369/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147428.4531 - mae: 147428.4531 - val_loss: 141555.6406 - val_mae: 141555.6406\n",
      "Epoch 370/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 144184.6250 - mae: 144184.6250 - val_loss: 141977.9219 - val_mae: 141977.9219\n",
      "Epoch 371/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143971.1406 - mae: 143971.1406 - val_loss: 140166.2656 - val_mae: 140166.2656\n",
      "Epoch 372/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144920.0312 - mae: 144920.0312 - val_loss: 138397.4062 - val_mae: 138397.4062\n",
      "Epoch 373/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143378.3281 - mae: 143378.3281 - val_loss: 141325.4375 - val_mae: 141325.4375\n",
      "Epoch 374/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144242.4062 - mae: 144242.4062 - val_loss: 146699.9062 - val_mae: 146699.9062\n",
      "Epoch 375/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144569.9531 - mae: 144569.9531 - val_loss: 146773.2031 - val_mae: 146773.2031\n",
      "Epoch 376/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142179.5938 - mae: 142179.5938 - val_loss: 139037.8906 - val_mae: 139037.8906\n",
      "Epoch 377/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144577.2500 - mae: 144577.2500 - val_loss: 136823.2656 - val_mae: 136823.2656\n",
      "Epoch 378/10000\n",
      "32/32 [==============================] - 0s 973us/step - loss: 142308.6719 - mae: 142308.6719 - val_loss: 144788.7500 - val_mae: 144788.7500\n",
      "Epoch 379/10000\n",
      "32/32 [==============================] - 0s 968us/step - loss: 143244.8125 - mae: 143244.8125 - val_loss: 141134.3594 - val_mae: 141134.3594\n",
      "Epoch 380/10000\n",
      "32/32 [==============================] - 0s 992us/step - loss: 143928.3125 - mae: 143928.3125 - val_loss: 143859.3594 - val_mae: 143859.3594\n",
      "Epoch 381/10000\n",
      "32/32 [==============================] - 0s 982us/step - loss: 143994.2969 - mae: 143994.2969 - val_loss: 137870.7500 - val_mae: 137870.7500\n",
      "Epoch 382/10000\n",
      "32/32 [==============================] - 0s 968us/step - loss: 142877.1406 - mae: 142877.1406 - val_loss: 138674.9219 - val_mae: 138674.9219\n",
      "Epoch 383/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143143.2812 - mae: 143143.2812 - val_loss: 142064.6094 - val_mae: 142064.6094\n",
      "Epoch 384/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 143166.0938 - mae: 143166.0938 - val_loss: 147048.7188 - val_mae: 147048.7188\n",
      "Epoch 385/10000\n",
      "32/32 [==============================] - 0s 971us/step - loss: 143573.4688 - mae: 143573.4688 - val_loss: 147785.0938 - val_mae: 147785.0938\n",
      "Epoch 386/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 144010.8906 - mae: 144010.8906 - val_loss: 137913.4688 - val_mae: 137913.4688\n",
      "Epoch 387/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143640.1094 - mae: 143640.1094 - val_loss: 138582.7188 - val_mae: 138582.7188\n",
      "Epoch 388/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 149127.3594 - mae: 149127.3594 - val_loss: 142731.5469 - val_mae: 142731.5469\n",
      "Epoch 389/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 143148.3594 - mae: 143148.3594 - val_loss: 141907.7500 - val_mae: 141907.7500\n",
      "Epoch 390/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142252.6719 - mae: 142252.6719 - val_loss: 140705.6250 - val_mae: 140705.6250\n",
      "Epoch 391/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142995.4062 - mae: 142995.4062 - val_loss: 137370.2344 - val_mae: 137370.2344\n",
      "Epoch 392/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 143031.6250 - mae: 143031.6250 - val_loss: 140181.3281 - val_mae: 140181.3281\n",
      "Epoch 393/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147399.8438 - mae: 147399.8438 - val_loss: 147047.8438 - val_mae: 147047.8438\n",
      "Epoch 394/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147635.3906 - mae: 147635.3906 - val_loss: 140566.0312 - val_mae: 140566.0312\n",
      "Epoch 395/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 142846.9844 - mae: 142846.9844 - val_loss: 140869.1562 - val_mae: 140869.1562\n",
      "Epoch 396/10000\n",
      "32/32 [==============================] - 0s 964us/step - loss: 143391.6719 - mae: 143391.6719 - val_loss: 143676.9219 - val_mae: 143676.9219\n",
      "Epoch 397/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142809.4219 - mae: 142809.4219 - val_loss: 146447.1875 - val_mae: 146447.1875\n",
      "Epoch 398/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142497.1562 - mae: 142497.1562 - val_loss: 137496.6875 - val_mae: 137496.6875\n",
      "Epoch 399/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 142021.6250 - mae: 142021.6250 - val_loss: 140542.1562 - val_mae: 140542.1562\n",
      "Epoch 400/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 143326.9219 - mae: 143326.9219 - val_loss: 138088.6250 - val_mae: 138088.6250\n",
      "Epoch 401/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143089.0781 - mae: 143089.0781 - val_loss: 142293.4062 - val_mae: 142293.4062\n",
      "Epoch 402/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147982.4219 - mae: 147982.4219 - val_loss: 155862.3906 - val_mae: 155862.3906\n",
      "Epoch 403/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 150270.4375 - mae: 150270.4375 - val_loss: 149285.6562 - val_mae: 149285.6562\n",
      "Epoch 404/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 149054.2969 - mae: 149054.2969 - val_loss: 144438.1875 - val_mae: 144438.1875\n",
      "Epoch 405/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143436.5781 - mae: 143436.5781 - val_loss: 144203.0000 - val_mae: 144203.0000\n",
      "Epoch 406/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143334.8438 - mae: 143334.8438 - val_loss: 137712.9688 - val_mae: 137712.9688\n",
      "Epoch 407/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143438.4531 - mae: 143438.4531 - val_loss: 140580.3906 - val_mae: 140580.3906\n",
      "Epoch 408/10000\n",
      "32/32 [==============================] - 0s 992us/step - loss: 141500.8281 - mae: 141500.8281 - val_loss: 138382.8125 - val_mae: 138382.8125\n",
      "Epoch 409/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142172.2500 - mae: 142172.2500 - val_loss: 146657.7656 - val_mae: 146657.7656\n",
      "Epoch 410/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 143354.7344 - mae: 143354.7344 - val_loss: 139706.5625 - val_mae: 139706.5625\n",
      "Epoch 411/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 142384.6250 - mae: 142384.6250 - val_loss: 140096.3594 - val_mae: 140096.3594\n",
      "Epoch 412/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143458.3125 - mae: 143458.3125 - val_loss: 139181.0156 - val_mae: 139181.0156\n",
      "Epoch 413/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144251.0625 - mae: 144251.0625 - val_loss: 151111.6719 - val_mae: 151111.6719\n",
      "Epoch 414/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144643.6094 - mae: 144643.6094 - val_loss: 139867.1250 - val_mae: 139867.1250\n",
      "Epoch 415/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142648.1094 - mae: 142648.1094 - val_loss: 138250.2969 - val_mae: 138250.2969\n",
      "Epoch 416/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144442.9375 - mae: 144442.9375 - val_loss: 139332.0938 - val_mae: 139332.0938\n",
      "Epoch 417/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142529.3438 - mae: 142529.3438 - val_loss: 139756.6250 - val_mae: 139756.6250\n",
      "Epoch 418/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141981.8750 - mae: 141981.8750 - val_loss: 139965.7344 - val_mae: 139965.7344\n",
      "Epoch 419/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143393.5312 - mae: 143393.5312 - val_loss: 139180.3438 - val_mae: 139180.3438\n",
      "Epoch 420/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143706.8594 - mae: 143706.8594 - val_loss: 137817.4062 - val_mae: 137817.4062\n",
      "Epoch 421/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143043.5781 - mae: 143043.5781 - val_loss: 137300.7344 - val_mae: 137300.7344\n",
      "Epoch 422/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 142982.3281 - mae: 142982.3281 - val_loss: 145712.2188 - val_mae: 145712.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423/10000\n",
      "32/32 [==============================] - 0s 980us/step - loss: 146518.6406 - mae: 146518.6406 - val_loss: 143341.8906 - val_mae: 143341.8906\n",
      "Epoch 424/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145169.2031 - mae: 145169.2031 - val_loss: 143168.9531 - val_mae: 143168.9531\n",
      "Epoch 425/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142198.9844 - mae: 142198.9844 - val_loss: 139958.7344 - val_mae: 139958.7344\n",
      "Epoch 426/10000\n",
      "32/32 [==============================] - 0s 984us/step - loss: 143386.2812 - mae: 143386.2812 - val_loss: 144464.9062 - val_mae: 144464.9062\n",
      "Epoch 427/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 145865.7969 - mae: 145865.7969 - val_loss: 142353.1875 - val_mae: 142353.1875\n",
      "Epoch 428/10000\n",
      "32/32 [==============================] - 0s 981us/step - loss: 142531.2188 - mae: 142531.2188 - val_loss: 144686.8594 - val_mae: 144686.8594\n",
      "Epoch 429/10000\n",
      "32/32 [==============================] - 0s 987us/step - loss: 143057.5312 - mae: 143057.5312 - val_loss: 143395.4375 - val_mae: 143395.4375\n",
      "Epoch 430/10000\n",
      "32/32 [==============================] - 0s 972us/step - loss: 145116.9219 - mae: 145116.9219 - val_loss: 140396.8125 - val_mae: 140396.8125\n",
      "Epoch 431/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143429.5312 - mae: 143429.5312 - val_loss: 141928.6719 - val_mae: 141928.6719\n",
      "Epoch 432/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 143920.2031 - mae: 143920.2031 - val_loss: 144889.8906 - val_mae: 144889.8906\n",
      "Epoch 433/10000\n",
      "32/32 [==============================] - 0s 962us/step - loss: 140789.5625 - mae: 140789.5625 - val_loss: 137935.5312 - val_mae: 137935.5312\n",
      "Epoch 434/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141238.1719 - mae: 141238.1719 - val_loss: 144082.4219 - val_mae: 144082.4219\n",
      "Epoch 435/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 142218.8750 - mae: 142218.8750 - val_loss: 142525.3906 - val_mae: 142525.3906\n",
      "Epoch 436/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143170.8281 - mae: 143170.8281 - val_loss: 141848.3281 - val_mae: 141848.3281\n",
      "Epoch 437/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143539.3125 - mae: 143539.3125 - val_loss: 141193.4375 - val_mae: 141193.4375\n",
      "Epoch 438/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 142875.9375 - mae: 142875.9375 - val_loss: 139454.9062 - val_mae: 139454.9062\n",
      "Epoch 439/10000\n",
      "32/32 [==============================] - 0s 980us/step - loss: 140848.8438 - mae: 140848.8438 - val_loss: 144629.9844 - val_mae: 144629.9844\n",
      "Epoch 440/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 142803.2969 - mae: 142803.2969 - val_loss: 141973.1562 - val_mae: 141973.1562\n",
      "Epoch 441/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143441.3906 - mae: 143441.3906 - val_loss: 143325.2656 - val_mae: 143325.2656\n",
      "Epoch 442/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144421.0625 - mae: 144421.0625 - val_loss: 137318.6406 - val_mae: 137318.6406\n",
      "Epoch 443/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141789.5000 - mae: 141789.5000 - val_loss: 143155.0938 - val_mae: 143155.0938\n",
      "Epoch 444/10000\n",
      "32/32 [==============================] - 0s 995us/step - loss: 142746.0781 - mae: 142746.0781 - val_loss: 145249.1406 - val_mae: 145249.1406\n",
      "Epoch 445/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142701.0469 - mae: 142701.0469 - val_loss: 143913.0938 - val_mae: 143913.0938\n",
      "Epoch 446/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142454.8281 - mae: 142454.8281 - val_loss: 139913.8438 - val_mae: 139913.8438\n",
      "Epoch 447/10000\n",
      "32/32 [==============================] - 0s 989us/step - loss: 140906.4062 - mae: 140906.4062 - val_loss: 140358.4844 - val_mae: 140358.4844\n",
      "Epoch 448/10000\n",
      "32/32 [==============================] - 0s 982us/step - loss: 145199.6875 - mae: 145199.6875 - val_loss: 139003.0938 - val_mae: 139003.0938\n",
      "Epoch 449/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 142449.3281 - mae: 142449.3281 - val_loss: 138104.6250 - val_mae: 138104.6250\n",
      "Epoch 450/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144049.5156 - mae: 144049.5156 - val_loss: 140950.2031 - val_mae: 140950.2031\n",
      "Epoch 451/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141121.5469 - mae: 141121.5469 - val_loss: 144784.5938 - val_mae: 144784.5938\n",
      "Epoch 452/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141773.0312 - mae: 141773.0312 - val_loss: 141554.4375 - val_mae: 141554.4375\n",
      "Epoch 453/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142263.0312 - mae: 142263.0312 - val_loss: 143616.9844 - val_mae: 143616.9844\n",
      "Epoch 454/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144985.6406 - mae: 144985.6406 - val_loss: 144408.9531 - val_mae: 144408.9531\n",
      "Epoch 455/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141662.2344 - mae: 141662.2344 - val_loss: 142955.1719 - val_mae: 142955.1719\n",
      "Epoch 456/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141762.3906 - mae: 141762.3906 - val_loss: 139931.9062 - val_mae: 139931.9062\n",
      "Epoch 457/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143294.1719 - mae: 143294.1719 - val_loss: 139237.8750 - val_mae: 139237.8750\n",
      "Epoch 458/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 142148.9844 - mae: 142148.9844 - val_loss: 140822.9375 - val_mae: 140822.9375\n",
      "Epoch 459/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140645.1250 - mae: 140645.1250 - val_loss: 138108.6094 - val_mae: 138108.6094\n",
      "Epoch 460/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142024.6406 - mae: 142024.6406 - val_loss: 140250.9375 - val_mae: 140250.9375\n",
      "Epoch 461/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 142829.2656 - mae: 142829.2656 - val_loss: 139861.5000 - val_mae: 139861.5000\n",
      "Epoch 462/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143904.8750 - mae: 143904.8750 - val_loss: 144573.7969 - val_mae: 144573.7969\n",
      "Epoch 463/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143295.3125 - mae: 143295.3125 - val_loss: 141528.3594 - val_mae: 141528.3594\n",
      "Epoch 464/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141373.1875 - mae: 141373.1875 - val_loss: 142756.0000 - val_mae: 142756.0000\n",
      "Epoch 465/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142456.0156 - mae: 142456.0156 - val_loss: 142272.1250 - val_mae: 142272.1250\n",
      "Epoch 466/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144075.5781 - mae: 144075.5781 - val_loss: 139753.3594 - val_mae: 139753.3594\n",
      "Epoch 467/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 141735.4844 - mae: 141735.4844 - val_loss: 147513.7344 - val_mae: 147513.7344\n",
      "Epoch 468/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143080.6875 - mae: 143080.6875 - val_loss: 136710.4062 - val_mae: 136710.4062\n",
      "Epoch 469/10000\n",
      "32/32 [==============================] - 0s 986us/step - loss: 140849.5781 - mae: 140849.5781 - val_loss: 140229.5625 - val_mae: 140229.5625\n",
      "Epoch 470/10000\n",
      "32/32 [==============================] - 0s 971us/step - loss: 141520.5781 - mae: 141520.5781 - val_loss: 138968.3750 - val_mae: 138968.3750\n",
      "Epoch 471/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142852.2812 - mae: 142852.2812 - val_loss: 136792.1875 - val_mae: 136792.1875\n",
      "Epoch 472/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 142760.0312 - mae: 142760.0312 - val_loss: 136132.1875 - val_mae: 136132.1875\n",
      "Epoch 473/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 143081.5156 - mae: 143081.5156 - val_loss: 141833.8281 - val_mae: 141833.8281\n",
      "Epoch 474/10000\n",
      "32/32 [==============================] - 0s 996us/step - loss: 141617.1875 - mae: 141617.1875 - val_loss: 142528.5312 - val_mae: 142528.5312\n",
      "Epoch 475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 143641.8750 - mae: 143641.8750 - val_loss: 142859.3906 - val_mae: 142859.3906\n",
      "Epoch 476/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144991.6875 - mae: 144991.6875 - val_loss: 145126.0781 - val_mae: 145126.0781\n",
      "Epoch 477/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 142446.9844 - mae: 142446.9844 - val_loss: 139985.3750 - val_mae: 139985.3750\n",
      "Epoch 478/10000\n",
      "32/32 [==============================] - 0s 985us/step - loss: 143192.5312 - mae: 143192.5312 - val_loss: 141429.7344 - val_mae: 141429.7344\n",
      "Epoch 479/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142312.3438 - mae: 142312.3438 - val_loss: 147538.2031 - val_mae: 147538.2031\n",
      "Epoch 480/10000\n",
      "32/32 [==============================] - 0s 986us/step - loss: 146818.3594 - mae: 146818.3594 - val_loss: 137102.1562 - val_mae: 137102.1562\n",
      "Epoch 481/10000\n",
      "32/32 [==============================] - 0s 972us/step - loss: 144347.0781 - mae: 144347.0781 - val_loss: 140407.0781 - val_mae: 140407.0781\n",
      "Epoch 482/10000\n",
      "32/32 [==============================] - 0s 987us/step - loss: 144942.0156 - mae: 144942.0156 - val_loss: 140829.8906 - val_mae: 140829.8906\n",
      "Epoch 483/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 146241.1562 - mae: 146241.1562 - val_loss: 148188.0625 - val_mae: 148188.0625\n",
      "Epoch 484/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144220.1875 - mae: 144220.1875 - val_loss: 144039.6250 - val_mae: 144039.6250\n",
      "Epoch 485/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143031.8750 - mae: 143031.8750 - val_loss: 139942.6875 - val_mae: 139942.6875\n",
      "Epoch 486/10000\n",
      "32/32 [==============================] - 0s 971us/step - loss: 142274.5625 - mae: 142274.5625 - val_loss: 142015.0938 - val_mae: 142015.0938\n",
      "Epoch 487/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141988.8750 - mae: 141988.8750 - val_loss: 137154.5312 - val_mae: 137154.5312\n",
      "Epoch 488/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 141453.5469 - mae: 141453.5469 - val_loss: 142633.3594 - val_mae: 142633.3594\n",
      "Epoch 489/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 141288.8906 - mae: 141288.8906 - val_loss: 136361.1094 - val_mae: 136361.1094\n",
      "Epoch 490/10000\n",
      "32/32 [==============================] - 0s 989us/step - loss: 141720.1875 - mae: 141720.1875 - val_loss: 143318.8438 - val_mae: 143318.8438\n",
      "Epoch 491/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143272.9688 - mae: 143272.9688 - val_loss: 140706.0156 - val_mae: 140706.0156\n",
      "Epoch 492/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 142037.2812 - mae: 142037.2812 - val_loss: 138163.9688 - val_mae: 138163.9688\n",
      "Epoch 493/10000\n",
      "32/32 [==============================] - 0s 983us/step - loss: 142061.4844 - mae: 142061.4844 - val_loss: 135985.5000 - val_mae: 135985.5000\n",
      "Epoch 494/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142865.2969 - mae: 142865.2969 - val_loss: 140654.9062 - val_mae: 140654.9062\n",
      "Epoch 495/10000\n",
      "32/32 [==============================] - 0s 985us/step - loss: 142315.6406 - mae: 142315.6406 - val_loss: 147363.8594 - val_mae: 147363.8594\n",
      "Epoch 496/10000\n",
      "32/32 [==============================] - 0s 982us/step - loss: 142637.3281 - mae: 142637.3281 - val_loss: 139113.3750 - val_mae: 139113.3750\n",
      "Epoch 497/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141801.4531 - mae: 141801.4531 - val_loss: 136054.4688 - val_mae: 136054.4688\n",
      "Epoch 498/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142229.3125 - mae: 142229.3125 - val_loss: 139537.1094 - val_mae: 139537.1094\n",
      "Epoch 499/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141555.4844 - mae: 141555.4844 - val_loss: 142006.8125 - val_mae: 142006.8125\n",
      "Epoch 500/10000\n",
      "32/32 [==============================] - 0s 985us/step - loss: 141271.0000 - mae: 141271.0000 - val_loss: 140687.6094 - val_mae: 140687.6094\n",
      "Epoch 501/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141044.0938 - mae: 141044.0938 - val_loss: 139834.0000 - val_mae: 139834.0000\n",
      "Epoch 502/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 140457.1719 - mae: 140457.1719 - val_loss: 137988.6094 - val_mae: 137988.6094\n",
      "Epoch 503/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147257.1562 - mae: 147257.1562 - val_loss: 156940.0938 - val_mae: 156940.0938\n",
      "Epoch 504/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 150282.8594 - mae: 150282.8594 - val_loss: 140521.0469 - val_mae: 140521.0469\n",
      "Epoch 505/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141206.0000 - mae: 141206.0000 - val_loss: 135934.2188 - val_mae: 135934.2188\n",
      "Epoch 506/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143430.9375 - mae: 143430.9375 - val_loss: 140885.5469 - val_mae: 140885.5469\n",
      "Epoch 507/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141242.2500 - mae: 141242.2500 - val_loss: 142939.8438 - val_mae: 142939.8438\n",
      "Epoch 508/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140732.8594 - mae: 140732.8594 - val_loss: 138826.9531 - val_mae: 138826.9531\n",
      "Epoch 509/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140901.9062 - mae: 140901.9062 - val_loss: 141793.5938 - val_mae: 141793.5938\n",
      "Epoch 510/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143473.6406 - mae: 143473.6406 - val_loss: 139188.1250 - val_mae: 139188.1250\n",
      "Epoch 511/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141582.5312 - mae: 141582.5312 - val_loss: 137688.5469 - val_mae: 137688.5469\n",
      "Epoch 512/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143514.7812 - mae: 143514.7812 - val_loss: 147139.0156 - val_mae: 147139.0156\n",
      "Epoch 513/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141541.2656 - mae: 141541.2656 - val_loss: 140059.6719 - val_mae: 140059.6719\n",
      "Epoch 514/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140029.3281 - mae: 140029.3281 - val_loss: 144041.9062 - val_mae: 144041.9062\n",
      "Epoch 515/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143305.8125 - mae: 143305.8125 - val_loss: 138978.1250 - val_mae: 138978.1250\n",
      "Epoch 516/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142628.4375 - mae: 142628.4375 - val_loss: 141645.2969 - val_mae: 141645.2969\n",
      "Epoch 517/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141063.0938 - mae: 141063.0938 - val_loss: 139949.5625 - val_mae: 139949.5625\n",
      "Epoch 518/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140712.5625 - mae: 140712.5625 - val_loss: 140346.3125 - val_mae: 140346.3125\n",
      "Epoch 519/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141101.2188 - mae: 141101.2188 - val_loss: 141861.7031 - val_mae: 141861.7031\n",
      "Epoch 520/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143981.9062 - mae: 143981.9062 - val_loss: 143683.9062 - val_mae: 143683.9062\n",
      "Epoch 521/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142227.6094 - mae: 142227.6094 - val_loss: 145290.4688 - val_mae: 145290.4688\n",
      "Epoch 522/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142582.5781 - mae: 142582.5781 - val_loss: 140079.4062 - val_mae: 140079.4062\n",
      "Epoch 523/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140668.9844 - mae: 140668.9844 - val_loss: 139319.3906 - val_mae: 139319.3906\n",
      "Epoch 524/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142340.0781 - mae: 142340.0781 - val_loss: 143408.8594 - val_mae: 143408.8594\n",
      "Epoch 525/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141438.1562 - mae: 141438.1562 - val_loss: 141307.4375 - val_mae: 141307.4375\n",
      "Epoch 526/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143213.7188 - mae: 143213.7188 - val_loss: 144948.8438 - val_mae: 144948.8438\n",
      "Epoch 527/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142494.2031 - mae: 142494.2031 - val_loss: 135441.1250 - val_mae: 135441.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142397.6094 - mae: 142397.6094 - val_loss: 140717.0000 - val_mae: 140717.0000\n",
      "Epoch 529/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142769.5000 - mae: 142769.5000 - val_loss: 141366.5312 - val_mae: 141366.5312\n",
      "Epoch 530/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140475.2969 - mae: 140475.2969 - val_loss: 140182.8125 - val_mae: 140182.8125\n",
      "Epoch 531/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141046.6719 - mae: 141046.6719 - val_loss: 138997.9688 - val_mae: 138997.9688\n",
      "Epoch 532/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 140697.7188 - mae: 140697.7188 - val_loss: 138214.7812 - val_mae: 138214.7812\n",
      "Epoch 533/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 144680.2500 - mae: 144680.2500 - val_loss: 138622.7969 - val_mae: 138622.7969\n",
      "Epoch 534/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141094.9688 - mae: 141094.9688 - val_loss: 135976.7031 - val_mae: 135976.7031\n",
      "Epoch 535/10000\n",
      "32/32 [==============================] - 0s 989us/step - loss: 140998.4531 - mae: 140998.4531 - val_loss: 141835.5312 - val_mae: 141835.5312\n",
      "Epoch 536/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 143542.7812 - mae: 143542.7812 - val_loss: 145329.2031 - val_mae: 145329.2031\n",
      "Epoch 537/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142238.9219 - mae: 142238.9219 - val_loss: 140487.9375 - val_mae: 140487.9375\n",
      "Epoch 538/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142086.2500 - mae: 142086.2500 - val_loss: 138497.6562 - val_mae: 138497.6562\n",
      "Epoch 539/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144742.9375 - mae: 144742.9375 - val_loss: 141436.7500 - val_mae: 141436.7500\n",
      "Epoch 540/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143789.2812 - mae: 143789.2812 - val_loss: 145526.5781 - val_mae: 145526.5781\n",
      "Epoch 541/10000\n",
      "32/32 [==============================] - 0s 982us/step - loss: 143320.8438 - mae: 143320.8438 - val_loss: 140491.5625 - val_mae: 140491.5625\n",
      "Epoch 542/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140134.6250 - mae: 140134.6250 - val_loss: 135369.7812 - val_mae: 135369.7812\n",
      "Epoch 543/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140801.8906 - mae: 140801.8906 - val_loss: 140740.8281 - val_mae: 140740.8281\n",
      "Epoch 544/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139543.2344 - mae: 139543.2344 - val_loss: 140795.1094 - val_mae: 140795.1094\n",
      "Epoch 545/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 144045.8750 - mae: 144045.8750 - val_loss: 143989.5938 - val_mae: 143989.5938\n",
      "Epoch 546/10000\n",
      "32/32 [==============================] - 0s 982us/step - loss: 144234.4688 - mae: 144234.4688 - val_loss: 139522.6406 - val_mae: 139522.6406\n",
      "Epoch 547/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 141512.8125 - mae: 141512.8125 - val_loss: 141126.2656 - val_mae: 141126.2656\n",
      "Epoch 548/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140440.3594 - mae: 140440.3594 - val_loss: 140838.7969 - val_mae: 140838.7969\n",
      "Epoch 549/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139769.2188 - mae: 139769.2188 - val_loss: 142536.8125 - val_mae: 142536.8125\n",
      "Epoch 550/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142924.7969 - mae: 142924.7969 - val_loss: 140520.6094 - val_mae: 140520.6094\n",
      "Epoch 551/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141042.9219 - mae: 141042.9219 - val_loss: 138760.0938 - val_mae: 138760.0938\n",
      "Epoch 552/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139780.2188 - mae: 139780.2188 - val_loss: 142037.3594 - val_mae: 142037.3594\n",
      "Epoch 553/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141992.2500 - mae: 141992.2500 - val_loss: 142655.7188 - val_mae: 142655.7188\n",
      "Epoch 554/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141561.6719 - mae: 141561.6719 - val_loss: 137387.1875 - val_mae: 137387.1875\n",
      "Epoch 555/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140728.0469 - mae: 140728.0469 - val_loss: 143158.7031 - val_mae: 143158.7031\n",
      "Epoch 556/10000\n",
      "32/32 [==============================] - 0s 987us/step - loss: 141527.7344 - mae: 141527.7344 - val_loss: 134474.1562 - val_mae: 134474.1562\n",
      "Epoch 557/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141219.2500 - mae: 141219.2500 - val_loss: 135639.9531 - val_mae: 135639.9531\n",
      "Epoch 558/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142135.0469 - mae: 142135.0469 - val_loss: 144228.4688 - val_mae: 144228.4688\n",
      "Epoch 559/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141389.4375 - mae: 141389.4375 - val_loss: 138494.6094 - val_mae: 138494.6094\n",
      "Epoch 560/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140629.5469 - mae: 140629.5469 - val_loss: 141497.1875 - val_mae: 141497.1875\n",
      "Epoch 561/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142148.9531 - mae: 142148.9531 - val_loss: 139371.2188 - val_mae: 139371.2188\n",
      "Epoch 562/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140212.4219 - mae: 140212.4219 - val_loss: 139521.5156 - val_mae: 139521.5156\n",
      "Epoch 563/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143230.1406 - mae: 143230.1406 - val_loss: 139721.8750 - val_mae: 139721.8750\n",
      "Epoch 564/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143996.7812 - mae: 143996.7812 - val_loss: 139101.2344 - val_mae: 139101.2344\n",
      "Epoch 565/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143072.0000 - mae: 143072.0000 - val_loss: 138597.2344 - val_mae: 138597.2344\n",
      "Epoch 566/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140630.9531 - mae: 140630.9531 - val_loss: 136645.2812 - val_mae: 136645.2812\n",
      "Epoch 567/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 142580.6094 - mae: 142580.6094 - val_loss: 138204.8125 - val_mae: 138204.8125\n",
      "Epoch 568/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140851.2812 - mae: 140851.2812 - val_loss: 139695.4688 - val_mae: 139695.4688\n",
      "Epoch 569/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139962.7969 - mae: 139962.7969 - val_loss: 140847.8750 - val_mae: 140847.8750\n",
      "Epoch 570/10000\n",
      "32/32 [==============================] - ETA: 0s - loss: 142979.7812 - mae: 142979.781 - 0s 1ms/step - loss: 143517.5156 - mae: 143517.5156 - val_loss: 141858.3594 - val_mae: 141858.3594\n",
      "Epoch 571/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141271.5156 - mae: 141271.5156 - val_loss: 137244.3906 - val_mae: 137244.3906\n",
      "Epoch 572/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142602.9531 - mae: 142602.9531 - val_loss: 143112.6250 - val_mae: 143112.6250\n",
      "Epoch 573/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140714.1562 - mae: 140714.1562 - val_loss: 143583.6406 - val_mae: 143583.6406\n",
      "Epoch 574/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 140391.3594 - mae: 140391.3594 - val_loss: 135938.3750 - val_mae: 135938.3750\n",
      "Epoch 575/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143402.9375 - mae: 143402.9375 - val_loss: 140810.1250 - val_mae: 140810.1250\n",
      "Epoch 576/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142909.9688 - mae: 142909.9688 - val_loss: 137138.6094 - val_mae: 137138.6094\n",
      "Epoch 577/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140321.5000 - mae: 140321.5000 - val_loss: 138394.7188 - val_mae: 138394.7188\n",
      "Epoch 578/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142166.1406 - mae: 142166.1406 - val_loss: 136800.7031 - val_mae: 136800.7031\n",
      "Epoch 579/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139968.8281 - mae: 139968.8281 - val_loss: 136000.4688 - val_mae: 136000.4688\n",
      "Epoch 580/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 142831.9219 - mae: 142831.9219 - val_loss: 138979.2656 - val_mae: 138979.2656\n",
      "Epoch 581/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140062.1719 - mae: 140062.1719 - val_loss: 134363.2344 - val_mae: 134363.2344\n",
      "Epoch 582/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 139654.9375 - mae: 139654.9375 - val_loss: 139590.3594 - val_mae: 139590.3594\n",
      "Epoch 583/10000\n",
      "32/32 [==============================] - 0s 996us/step - loss: 140800.7188 - mae: 140800.7188 - val_loss: 137485.6406 - val_mae: 137485.6406\n",
      "Epoch 584/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140643.5625 - mae: 140643.5625 - val_loss: 136078.1875 - val_mae: 136078.1875\n",
      "Epoch 585/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144745.1406 - mae: 144745.1406 - val_loss: 143746.2656 - val_mae: 143746.2656\n",
      "Epoch 586/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142328.6875 - mae: 142328.6875 - val_loss: 140051.1094 - val_mae: 140051.1094\n",
      "Epoch 587/10000\n",
      "32/32 [==============================] - 0s 984us/step - loss: 141460.5000 - mae: 141460.5000 - val_loss: 141073.7344 - val_mae: 141073.7344\n",
      "Epoch 588/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139649.2656 - mae: 139649.2656 - val_loss: 147614.0938 - val_mae: 147614.0938\n",
      "Epoch 589/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142194.2188 - mae: 142194.2188 - val_loss: 144542.4375 - val_mae: 144542.4375\n",
      "Epoch 590/10000\n",
      "32/32 [==============================] - 0s 984us/step - loss: 140200.8438 - mae: 140200.8438 - val_loss: 140161.3594 - val_mae: 140161.3594\n",
      "Epoch 591/10000\n",
      "32/32 [==============================] - 0s 969us/step - loss: 146482.1250 - mae: 146482.1250 - val_loss: 146820.3281 - val_mae: 146820.3281\n",
      "Epoch 592/10000\n",
      "32/32 [==============================] - 0s 986us/step - loss: 142261.9062 - mae: 142261.9062 - val_loss: 140862.1875 - val_mae: 140862.1875\n",
      "Epoch 593/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139665.7812 - mae: 139665.7812 - val_loss: 141280.2031 - val_mae: 141280.2031\n",
      "Epoch 594/10000\n",
      "32/32 [==============================] - 0s 987us/step - loss: 140441.5000 - mae: 140441.5000 - val_loss: 137200.6406 - val_mae: 137200.6406\n",
      "Epoch 595/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141476.5312 - mae: 141476.5312 - val_loss: 139778.1719 - val_mae: 139778.1719\n",
      "Epoch 596/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140043.3281 - mae: 140043.3281 - val_loss: 138794.2969 - val_mae: 138794.2969\n",
      "Epoch 597/10000\n",
      "32/32 [==============================] - 0s 955us/step - loss: 141326.0469 - mae: 141326.0469 - val_loss: 143260.8438 - val_mae: 143260.8438\n",
      "Epoch 598/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 146968.2344 - mae: 146968.2344 - val_loss: 154364.3125 - val_mae: 154364.3125\n",
      "Epoch 599/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 142097.5156 - mae: 142097.5156 - val_loss: 139174.1562 - val_mae: 139174.1562\n",
      "Epoch 600/10000\n",
      "32/32 [==============================] - 0s 995us/step - loss: 144645.8594 - mae: 144645.8594 - val_loss: 147033.4688 - val_mae: 147033.4688\n",
      "Epoch 601/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142678.7969 - mae: 142678.7969 - val_loss: 152585.2031 - val_mae: 152585.2031\n",
      "Epoch 602/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144299.0781 - mae: 144299.0781 - val_loss: 139693.5938 - val_mae: 139693.5938\n",
      "Epoch 603/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139469.6406 - mae: 139469.6406 - val_loss: 140372.2812 - val_mae: 140372.2812\n",
      "Epoch 604/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140297.9844 - mae: 140297.9844 - val_loss: 138897.6094 - val_mae: 138897.6094\n",
      "Epoch 605/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143488.8594 - mae: 143488.8594 - val_loss: 142543.4219 - val_mae: 142543.4219\n",
      "Epoch 606/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141930.1406 - mae: 141930.1406 - val_loss: 136617.0469 - val_mae: 136617.0469\n",
      "Epoch 607/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 143218.7656 - mae: 143218.7656 - val_loss: 136431.1250 - val_mae: 136431.1250\n",
      "Epoch 608/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141839.2500 - mae: 141839.2500 - val_loss: 137667.8125 - val_mae: 137667.8125\n",
      "Epoch 609/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143051.5000 - mae: 143051.5000 - val_loss: 143309.1719 - val_mae: 143309.1719\n",
      "Epoch 610/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140758.4844 - mae: 140758.4844 - val_loss: 142796.3906 - val_mae: 142796.3906\n",
      "Epoch 611/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139980.3281 - mae: 139980.3281 - val_loss: 139160.5938 - val_mae: 139160.5938\n",
      "Epoch 612/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141023.0000 - mae: 141023.0000 - val_loss: 142577.2188 - val_mae: 142577.2188\n",
      "Epoch 613/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141688.1094 - mae: 141688.1094 - val_loss: 139442.5625 - val_mae: 139442.5625\n",
      "Epoch 614/10000\n",
      "32/32 [==============================] - 0s 989us/step - loss: 140536.6250 - mae: 140536.6250 - val_loss: 140907.3125 - val_mae: 140907.3125\n",
      "Epoch 615/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139969.5312 - mae: 139969.5312 - val_loss: 140527.4688 - val_mae: 140527.4688\n",
      "Epoch 616/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139090.4375 - mae: 139090.4375 - val_loss: 140288.6719 - val_mae: 140288.6719\n",
      "Epoch 617/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139414.6719 - mae: 139414.6719 - val_loss: 140773.0156 - val_mae: 140773.0156\n",
      "Epoch 618/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139786.9844 - mae: 139786.9844 - val_loss: 143448.4375 - val_mae: 143448.4375\n",
      "Epoch 619/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140820.3750 - mae: 140820.3750 - val_loss: 138209.4688 - val_mae: 138209.4688\n",
      "Epoch 620/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 141932.7344 - mae: 141932.7344 - val_loss: 142155.5625 - val_mae: 142155.5625\n",
      "Epoch 621/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142215.0000 - mae: 142215.0000 - val_loss: 145677.2656 - val_mae: 145677.2656\n",
      "Epoch 622/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143274.8750 - mae: 143274.8750 - val_loss: 145660.4688 - val_mae: 145660.4688\n",
      "Epoch 623/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140856.5625 - mae: 140856.5625 - val_loss: 144985.0781 - val_mae: 144985.0781\n",
      "Epoch 624/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140069.4062 - mae: 140069.4062 - val_loss: 142765.2812 - val_mae: 142765.2812\n",
      "Epoch 625/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142058.2812 - mae: 142058.2812 - val_loss: 136031.7656 - val_mae: 136031.7656\n",
      "Epoch 626/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141314.0938 - mae: 141314.0938 - val_loss: 141426.9531 - val_mae: 141426.9531\n",
      "Epoch 627/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141040.4062 - mae: 141040.4062 - val_loss: 140055.6719 - val_mae: 140055.6719\n",
      "Epoch 628/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139618.7500 - mae: 139618.7500 - val_loss: 141906.4844 - val_mae: 141906.4844\n",
      "Epoch 629/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140971.1250 - mae: 140971.1250 - val_loss: 143362.5781 - val_mae: 143362.5781\n",
      "Epoch 630/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140132.5469 - mae: 140132.5469 - val_loss: 138093.4219 - val_mae: 138093.4219\n",
      "Epoch 631/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140021.5469 - mae: 140021.5469 - val_loss: 139020.7344 - val_mae: 139020.7344\n",
      "Epoch 632/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139107.3125 - mae: 139107.3125 - val_loss: 141505.7344 - val_mae: 141505.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 633/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141012.7188 - mae: 141012.7188 - val_loss: 138808.1562 - val_mae: 138808.1562\n",
      "Epoch 634/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139521.8750 - mae: 139521.8750 - val_loss: 140486.9844 - val_mae: 140486.9844\n",
      "Epoch 635/10000\n",
      "32/32 [==============================] - 0s 978us/step - loss: 138805.5781 - mae: 138805.5781 - val_loss: 139204.6719 - val_mae: 139204.6719\n",
      "Epoch 636/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140280.1875 - mae: 140280.1875 - val_loss: 151605.3906 - val_mae: 151605.3906\n",
      "Epoch 637/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143640.9531 - mae: 143640.9531 - val_loss: 137451.6094 - val_mae: 137451.6094\n",
      "Epoch 638/10000\n",
      "32/32 [==============================] - 0s 996us/step - loss: 139202.9062 - mae: 139202.9062 - val_loss: 134940.6406 - val_mae: 134940.6406\n",
      "Epoch 639/10000\n",
      "32/32 [==============================] - 0s 989us/step - loss: 139390.1562 - mae: 139390.1562 - val_loss: 143296.1250 - val_mae: 143296.1250\n",
      "Epoch 640/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141544.3594 - mae: 141544.3594 - val_loss: 145844.1250 - val_mae: 145844.1250\n",
      "Epoch 641/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145401.0625 - mae: 145401.0625 - val_loss: 140470.9531 - val_mae: 140470.9531\n",
      "Epoch 642/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141270.7344 - mae: 141270.7344 - val_loss: 141254.8906 - val_mae: 141254.8906\n",
      "Epoch 643/10000\n",
      "32/32 [==============================] - 0s 986us/step - loss: 140904.6094 - mae: 140904.6094 - val_loss: 144547.3750 - val_mae: 144547.3750\n",
      "Epoch 644/10000\n",
      "32/32 [==============================] - 0s 975us/step - loss: 140325.2656 - mae: 140325.2656 - val_loss: 140793.7031 - val_mae: 140793.7031\n",
      "Epoch 645/10000\n",
      "32/32 [==============================] - 0s 962us/step - loss: 140834.7656 - mae: 140834.7656 - val_loss: 140724.2188 - val_mae: 140724.2188\n",
      "Epoch 646/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 140686.2500 - mae: 140686.2500 - val_loss: 140840.1719 - val_mae: 140840.1719\n",
      "Epoch 647/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 139695.8438 - mae: 139695.8438 - val_loss: 138250.6094 - val_mae: 138250.6094\n",
      "Epoch 648/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 139364.1719 - mae: 139364.1719 - val_loss: 147024.0000 - val_mae: 147024.0000\n",
      "Epoch 649/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 141894.5156 - mae: 141894.5156 - val_loss: 138722.2969 - val_mae: 138722.2969\n",
      "Epoch 650/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141521.6719 - mae: 141521.6719 - val_loss: 141627.4688 - val_mae: 141627.4688\n",
      "Epoch 651/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140102.6250 - mae: 140102.6250 - val_loss: 137573.4375 - val_mae: 137573.4375\n",
      "Epoch 652/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 140774.5938 - mae: 140774.5938 - val_loss: 137814.2969 - val_mae: 137814.2969\n",
      "Epoch 653/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141309.1094 - mae: 141309.1094 - val_loss: 139469.9531 - val_mae: 139469.9531\n",
      "Epoch 654/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140763.5156 - mae: 140763.5156 - val_loss: 140966.7656 - val_mae: 140966.7656\n",
      "Epoch 655/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 139153.2344 - mae: 139153.2344 - val_loss: 138011.3125 - val_mae: 138011.3125\n",
      "Epoch 656/10000\n",
      "32/32 [==============================] - 0s 975us/step - loss: 139454.5312 - mae: 139454.5312 - val_loss: 141425.5625 - val_mae: 141425.5625\n",
      "Epoch 657/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143365.8125 - mae: 143365.8125 - val_loss: 139078.6406 - val_mae: 139078.6406\n",
      "Epoch 658/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142609.0312 - mae: 142609.0312 - val_loss: 143749.2656 - val_mae: 143749.2656\n",
      "Epoch 659/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139441.7500 - mae: 139441.7500 - val_loss: 137041.9219 - val_mae: 137041.9219\n",
      "Epoch 660/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140467.6562 - mae: 140467.6562 - val_loss: 141287.5312 - val_mae: 141287.5312\n",
      "Epoch 661/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139628.7812 - mae: 139628.7812 - val_loss: 137962.6719 - val_mae: 137962.6719\n",
      "Epoch 662/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 139467.2656 - mae: 139467.2656 - val_loss: 135737.0469 - val_mae: 135737.0469\n",
      "Epoch 663/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138306.6094 - mae: 138306.6094 - val_loss: 138191.4844 - val_mae: 138191.4844\n",
      "Epoch 664/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144706.2969 - mae: 144706.2969 - val_loss: 140811.3906 - val_mae: 140811.3906\n",
      "Epoch 665/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140357.5469 - mae: 140357.5469 - val_loss: 139914.7812 - val_mae: 139914.7812\n",
      "Epoch 666/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139006.0000 - mae: 139006.0000 - val_loss: 137353.5312 - val_mae: 137353.5312\n",
      "Epoch 667/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143067.3906 - mae: 143067.3906 - val_loss: 146761.6250 - val_mae: 146761.6250\n",
      "Epoch 668/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140633.3438 - mae: 140633.3438 - val_loss: 138675.1562 - val_mae: 138675.1562\n",
      "Epoch 669/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138373.2344 - mae: 138373.2344 - val_loss: 137559.6250 - val_mae: 137559.6250\n",
      "Epoch 670/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139667.9219 - mae: 139667.9219 - val_loss: 137591.5000 - val_mae: 137591.5000\n",
      "Epoch 671/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138351.0625 - mae: 138351.0625 - val_loss: 144501.2344 - val_mae: 144501.2344\n",
      "Epoch 672/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139442.0938 - mae: 139442.0938 - val_loss: 140069.1719 - val_mae: 140069.1719\n",
      "Epoch 673/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138770.1875 - mae: 138770.1875 - val_loss: 140192.0938 - val_mae: 140192.0938\n",
      "Epoch 674/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139217.2969 - mae: 139217.2969 - val_loss: 137111.8281 - val_mae: 137111.8281\n",
      "Epoch 675/10000\n",
      "32/32 [==============================] - 0s 992us/step - loss: 138256.3281 - mae: 138256.3281 - val_loss: 135988.8281 - val_mae: 135988.8281\n",
      "Epoch 676/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138875.7969 - mae: 138875.7969 - val_loss: 139997.8750 - val_mae: 139997.8750\n",
      "Epoch 677/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139883.2188 - mae: 139883.2188 - val_loss: 141509.9688 - val_mae: 141509.9688\n",
      "Epoch 678/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144587.5469 - mae: 144587.5469 - val_loss: 140326.1250 - val_mae: 140326.1250\n",
      "Epoch 679/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 145819.6406 - mae: 145819.6406 - val_loss: 142082.1094 - val_mae: 142082.1094\n",
      "Epoch 680/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 140493.2344 - mae: 140493.2344 - val_loss: 141427.7188 - val_mae: 141427.7188\n",
      "Epoch 681/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138079.2812 - mae: 138079.2812 - val_loss: 147092.5469 - val_mae: 147092.5469\n",
      "Epoch 682/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142186.2656 - mae: 142186.2656 - val_loss: 139260.4219 - val_mae: 139260.4219\n",
      "Epoch 683/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 138546.4688 - mae: 138546.4688 - val_loss: 140189.5156 - val_mae: 140189.5156\n",
      "Epoch 684/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137983.1562 - mae: 137983.1562 - val_loss: 138081.3594 - val_mae: 138081.3594\n",
      "Epoch 685/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 139616.4375 - mae: 139616.4375 - val_loss: 136790.7812 - val_mae: 136790.7812\n",
      "Epoch 686/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141325.8594 - mae: 141325.8594 - val_loss: 136728.6406 - val_mae: 136728.6406\n",
      "Epoch 687/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138004.0938 - mae: 138004.0938 - val_loss: 141058.4688 - val_mae: 141058.4688\n",
      "Epoch 688/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 139211.6875 - mae: 139211.6875 - val_loss: 141335.7812 - val_mae: 141335.7812\n",
      "Epoch 689/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 138893.1406 - mae: 138893.1406 - val_loss: 144425.2500 - val_mae: 144425.2500\n",
      "Epoch 690/10000\n",
      "32/32 [==============================] - 0s 964us/step - loss: 140348.6250 - mae: 140348.6250 - val_loss: 139695.2500 - val_mae: 139695.2500\n",
      "Epoch 691/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138084.3438 - mae: 138084.3438 - val_loss: 138355.1875 - val_mae: 138355.1875\n",
      "Epoch 692/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 139368.5469 - mae: 139368.5469 - val_loss: 139765.0781 - val_mae: 139765.0781\n",
      "Epoch 693/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141444.5156 - mae: 141444.5156 - val_loss: 140726.6719 - val_mae: 140726.6719\n",
      "Epoch 694/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140681.8125 - mae: 140681.8125 - val_loss: 165748.8750 - val_mae: 165748.8750\n",
      "Epoch 695/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144218.7188 - mae: 144218.7188 - val_loss: 138631.5000 - val_mae: 138631.5000\n",
      "Epoch 696/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139166.4219 - mae: 139166.4219 - val_loss: 135231.7500 - val_mae: 135231.7500\n",
      "Epoch 697/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139456.2188 - mae: 139456.2188 - val_loss: 142623.0312 - val_mae: 142623.0312\n",
      "Epoch 698/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138287.8750 - mae: 138287.8750 - val_loss: 137932.4062 - val_mae: 137932.4062\n",
      "Epoch 699/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140695.0938 - mae: 140695.0938 - val_loss: 140881.6406 - val_mae: 140881.6406\n",
      "Epoch 700/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140235.1406 - mae: 140235.1406 - val_loss: 140636.7031 - val_mae: 140636.7031\n",
      "Epoch 701/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139138.0938 - mae: 139138.0938 - val_loss: 137969.1562 - val_mae: 137969.1562\n",
      "Epoch 702/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139998.0938 - mae: 139998.0938 - val_loss: 145797.7031 - val_mae: 145797.7031\n",
      "Epoch 703/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141702.7812 - mae: 141702.7812 - val_loss: 137673.1250 - val_mae: 137673.1250\n",
      "Epoch 704/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 139058.0938 - mae: 139058.0938 - val_loss: 139729.8438 - val_mae: 139729.8438\n",
      "Epoch 705/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141104.3750 - mae: 141104.3750 - val_loss: 141947.7969 - val_mae: 141947.7969\n",
      "Epoch 706/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140029.5625 - mae: 140029.5625 - val_loss: 147187.9062 - val_mae: 147187.9062\n",
      "Epoch 707/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141254.2344 - mae: 141254.2344 - val_loss: 139249.7031 - val_mae: 139249.7031\n",
      "Epoch 708/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137969.3906 - mae: 137969.3906 - val_loss: 139005.1562 - val_mae: 139005.1562\n",
      "Epoch 709/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137744.6406 - mae: 137744.6406 - val_loss: 138020.3906 - val_mae: 138020.3906\n",
      "Epoch 710/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139865.0781 - mae: 139865.0781 - val_loss: 138333.0000 - val_mae: 138333.0000\n",
      "Epoch 711/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141940.8438 - mae: 141940.8438 - val_loss: 141655.5156 - val_mae: 141655.5156\n",
      "Epoch 712/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139124.9062 - mae: 139124.9062 - val_loss: 136367.6406 - val_mae: 136367.6406\n",
      "Epoch 713/10000\n",
      "32/32 [==============================] - 0s 987us/step - loss: 140034.6875 - mae: 140034.6875 - val_loss: 137324.3594 - val_mae: 137324.3594\n",
      "Epoch 714/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 138217.8438 - mae: 138217.8438 - val_loss: 141018.7031 - val_mae: 141018.7031\n",
      "Epoch 715/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140176.0469 - mae: 140176.0469 - val_loss: 140054.6094 - val_mae: 140054.6094\n",
      "Epoch 716/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138577.4688 - mae: 138577.4688 - val_loss: 145665.7188 - val_mae: 145665.7188\n",
      "Epoch 717/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141921.1875 - mae: 141921.1875 - val_loss: 138588.3906 - val_mae: 138588.3906\n",
      "Epoch 718/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 144101.0312 - mae: 144101.0312 - val_loss: 137712.2344 - val_mae: 137712.2344\n",
      "Epoch 719/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139529.5625 - mae: 139529.5625 - val_loss: 136618.9688 - val_mae: 136618.9688\n",
      "Epoch 720/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140350.6875 - mae: 140350.6875 - val_loss: 134078.6562 - val_mae: 134078.6562\n",
      "Epoch 721/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138419.5312 - mae: 138419.5312 - val_loss: 134310.2500 - val_mae: 134310.2500\n",
      "Epoch 722/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139655.5312 - mae: 139655.5312 - val_loss: 139815.3594 - val_mae: 139815.3594\n",
      "Epoch 723/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138766.0625 - mae: 138766.0625 - val_loss: 141117.2188 - val_mae: 141117.2188\n",
      "Epoch 724/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139481.5938 - mae: 139481.5938 - val_loss: 143881.2188 - val_mae: 143881.2188\n",
      "Epoch 725/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138375.9531 - mae: 138375.9531 - val_loss: 144388.5312 - val_mae: 144388.5312\n",
      "Epoch 726/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137850.5625 - mae: 137850.5625 - val_loss: 137597.5781 - val_mae: 137597.5781\n",
      "Epoch 727/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137419.7969 - mae: 137419.7969 - val_loss: 137199.0000 - val_mae: 137199.0000\n",
      "Epoch 728/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140420.3281 - mae: 140420.3281 - val_loss: 140885.3906 - val_mae: 140885.3906\n",
      "Epoch 729/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138724.6719 - mae: 138724.6719 - val_loss: 138758.7344 - val_mae: 138758.7344\n",
      "Epoch 730/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137048.3906 - mae: 137048.3906 - val_loss: 137231.8438 - val_mae: 137231.8438\n",
      "Epoch 731/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136608.8438 - mae: 136608.8438 - val_loss: 134447.2656 - val_mae: 134447.2656\n",
      "Epoch 732/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137614.4844 - mae: 137614.4844 - val_loss: 138910.8906 - val_mae: 138910.8906\n",
      "Epoch 733/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136917.1875 - mae: 136917.1875 - val_loss: 139808.7812 - val_mae: 139808.7812\n",
      "Epoch 734/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139397.2969 - mae: 139397.2969 - val_loss: 144580.0156 - val_mae: 144580.0156\n",
      "Epoch 735/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137888.3906 - mae: 137888.3906 - val_loss: 153930.3438 - val_mae: 153930.3438\n",
      "Epoch 736/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141546.2969 - mae: 141546.2969 - val_loss: 142694.7812 - val_mae: 142694.7812\n",
      "Epoch 737/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138829.5781 - mae: 138829.5781 - val_loss: 137333.7656 - val_mae: 137333.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 738/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138575.4062 - mae: 138575.4062 - val_loss: 135800.3281 - val_mae: 135800.3281\n",
      "Epoch 739/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 138005.4688 - mae: 138005.4688 - val_loss: 137089.8438 - val_mae: 137089.8438\n",
      "Epoch 740/10000\n",
      "32/32 [==============================] - 0s 985us/step - loss: 137726.2969 - mae: 137726.2969 - val_loss: 138105.2656 - val_mae: 138105.2656\n",
      "Epoch 741/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 136392.9531 - mae: 136392.9531 - val_loss: 137657.7031 - val_mae: 137657.7031\n",
      "Epoch 742/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138559.7500 - mae: 138559.7500 - val_loss: 142150.1250 - val_mae: 142150.1250\n",
      "Epoch 743/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141038.1562 - mae: 141038.1562 - val_loss: 137643.0469 - val_mae: 137643.0469\n",
      "Epoch 744/10000\n",
      "32/32 [==============================] - 0s 981us/step - loss: 139397.0156 - mae: 139397.0156 - val_loss: 142143.2969 - val_mae: 142143.2969\n",
      "Epoch 745/10000\n",
      "32/32 [==============================] - 0s 976us/step - loss: 140464.7656 - mae: 140464.7656 - val_loss: 139998.5469 - val_mae: 139998.5469\n",
      "Epoch 746/10000\n",
      "32/32 [==============================] - 0s 986us/step - loss: 140563.7656 - mae: 140563.7656 - val_loss: 152152.2344 - val_mae: 152152.2344\n",
      "Epoch 747/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140353.1406 - mae: 140353.1406 - val_loss: 138727.2031 - val_mae: 138727.2031\n",
      "Epoch 748/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 137133.2656 - mae: 137133.2656 - val_loss: 136844.0156 - val_mae: 136844.0156\n",
      "Epoch 749/10000\n",
      "32/32 [==============================] - 0s 980us/step - loss: 138557.8125 - mae: 138557.8125 - val_loss: 136864.8594 - val_mae: 136864.8594\n",
      "Epoch 750/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 139103.9531 - mae: 139103.9531 - val_loss: 136503.8125 - val_mae: 136503.8125\n",
      "Epoch 751/10000\n",
      "32/32 [==============================] - 0s 999us/step - loss: 138313.2031 - mae: 138313.2031 - val_loss: 141736.6719 - val_mae: 141736.6719\n",
      "Epoch 752/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136615.9531 - mae: 136615.9531 - val_loss: 139979.7344 - val_mae: 139979.7344\n",
      "Epoch 753/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138204.5938 - mae: 138204.5938 - val_loss: 143898.2031 - val_mae: 143898.2031\n",
      "Epoch 754/10000\n",
      "32/32 [==============================] - 0s 996us/step - loss: 138504.4688 - mae: 138504.4688 - val_loss: 136741.6875 - val_mae: 136741.6875\n",
      "Epoch 755/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136678.6250 - mae: 136678.6250 - val_loss: 143695.0938 - val_mae: 143695.0938\n",
      "Epoch 756/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139302.8438 - mae: 139302.8438 - val_loss: 139392.6562 - val_mae: 139392.6562\n",
      "Epoch 757/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137006.2812 - mae: 137006.2812 - val_loss: 146010.5938 - val_mae: 146010.5938\n",
      "Epoch 758/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 136631.6719 - mae: 136631.6719 - val_loss: 139105.4062 - val_mae: 139105.4062\n",
      "Epoch 759/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 138517.7969 - mae: 138517.7969 - val_loss: 134049.3438 - val_mae: 134049.3438\n",
      "Epoch 760/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138093.9531 - mae: 138093.9531 - val_loss: 139330.8750 - val_mae: 139330.8750\n",
      "Epoch 761/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138218.7500 - mae: 138218.7500 - val_loss: 142209.4844 - val_mae: 142209.4844\n",
      "Epoch 762/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136890.8750 - mae: 136890.8750 - val_loss: 141230.1719 - val_mae: 141230.1719\n",
      "Epoch 763/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136627.8906 - mae: 136627.8906 - val_loss: 142722.2188 - val_mae: 142722.2188\n",
      "Epoch 764/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138768.2500 - mae: 138768.2500 - val_loss: 139698.4375 - val_mae: 139698.4375\n",
      "Epoch 765/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137067.5000 - mae: 137067.5000 - val_loss: 139262.4688 - val_mae: 139262.4688\n",
      "Epoch 766/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 136477.9375 - mae: 136477.9375 - val_loss: 140046.3594 - val_mae: 140046.3594\n",
      "Epoch 767/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137411.2812 - mae: 137411.2812 - val_loss: 142363.6094 - val_mae: 142363.6094\n",
      "Epoch 768/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138159.9375 - mae: 138159.9375 - val_loss: 140869.5312 - val_mae: 140869.5312\n",
      "Epoch 769/10000\n",
      "32/32 [==============================] - 0s 982us/step - loss: 135885.8281 - mae: 135885.8281 - val_loss: 140894.4375 - val_mae: 140894.4375\n",
      "Epoch 770/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 135618.6719 - mae: 135618.6719 - val_loss: 138642.8438 - val_mae: 138642.8438\n",
      "Epoch 771/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137625.1875 - mae: 137625.1875 - val_loss: 144663.6094 - val_mae: 144663.6094\n",
      "Epoch 772/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139221.8906 - mae: 139221.8906 - val_loss: 141436.4844 - val_mae: 141436.4844\n",
      "Epoch 773/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136479.4844 - mae: 136479.4844 - val_loss: 141190.2969 - val_mae: 141190.2969\n",
      "Epoch 774/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138421.6875 - mae: 138421.6875 - val_loss: 140348.9062 - val_mae: 140348.9062\n",
      "Epoch 775/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136923.2188 - mae: 136923.2188 - val_loss: 140132.2344 - val_mae: 140132.2344\n",
      "Epoch 776/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139308.7031 - mae: 139308.7031 - val_loss: 139915.5469 - val_mae: 139915.5469\n",
      "Epoch 777/10000\n",
      "32/32 [==============================] - 0s 988us/step - loss: 142936.1875 - mae: 142936.1875 - val_loss: 146259.2500 - val_mae: 146259.2500\n",
      "Epoch 778/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 139025.7188 - mae: 139025.7188 - val_loss: 140946.9531 - val_mae: 140946.9531\n",
      "Epoch 779/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136843.7500 - mae: 136843.7500 - val_loss: 136493.9531 - val_mae: 136493.9531\n",
      "Epoch 780/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140390.9375 - mae: 140390.9375 - val_loss: 137282.1406 - val_mae: 137282.1406\n",
      "Epoch 781/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143742.3438 - mae: 143742.3438 - val_loss: 161414.7500 - val_mae: 161414.7500\n",
      "Epoch 782/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 147653.7969 - mae: 147653.7969 - val_loss: 140596.9844 - val_mae: 140596.9844\n",
      "Epoch 783/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 142574.2969 - mae: 142574.2969 - val_loss: 151113.2812 - val_mae: 151113.2812\n",
      "Epoch 784/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140675.7188 - mae: 140675.7188 - val_loss: 144653.8594 - val_mae: 144653.8594\n",
      "Epoch 785/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136297.5156 - mae: 136297.5156 - val_loss: 138702.3750 - val_mae: 138702.3750\n",
      "Epoch 786/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138395.1406 - mae: 138395.1406 - val_loss: 135083.6719 - val_mae: 135083.6719\n",
      "Epoch 787/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137548.3438 - mae: 137548.3438 - val_loss: 137718.6719 - val_mae: 137718.6719\n",
      "Epoch 788/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136292.8125 - mae: 136292.8125 - val_loss: 137589.9688 - val_mae: 137589.9688\n",
      "Epoch 789/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136842.0625 - mae: 136842.0625 - val_loss: 138148.3594 - val_mae: 138148.3594\n",
      "Epoch 790/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step - loss: 136500.7500 - mae: 136500.7500 - val_loss: 140599.0469 - val_mae: 140599.0469\n",
      "Epoch 791/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137103.3750 - mae: 137103.3750 - val_loss: 138887.8281 - val_mae: 138887.8281\n",
      "Epoch 792/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136179.6406 - mae: 136179.6406 - val_loss: 135357.2656 - val_mae: 135357.2656\n",
      "Epoch 793/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136655.7656 - mae: 136655.7656 - val_loss: 139304.5156 - val_mae: 139304.5156\n",
      "Epoch 794/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136073.4844 - mae: 136073.4844 - val_loss: 144092.4844 - val_mae: 144092.4844\n",
      "Epoch 795/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137605.3125 - mae: 137605.3125 - val_loss: 135084.1719 - val_mae: 135084.1719\n",
      "Epoch 796/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135948.6406 - mae: 135948.6406 - val_loss: 136869.5938 - val_mae: 136869.5938\n",
      "Epoch 797/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137812.2031 - mae: 137812.2031 - val_loss: 136857.4062 - val_mae: 136857.4062\n",
      "Epoch 798/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137558.5781 - mae: 137558.5781 - val_loss: 135372.5000 - val_mae: 135372.5000\n",
      "Epoch 799/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137662.3750 - mae: 137662.3750 - val_loss: 139471.2031 - val_mae: 139471.2031\n",
      "Epoch 800/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137798.0781 - mae: 137798.0781 - val_loss: 139019.0781 - val_mae: 139019.0781\n",
      "Epoch 801/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136694.1875 - mae: 136694.1875 - val_loss: 139410.0312 - val_mae: 139410.0312\n",
      "Epoch 802/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 136842.0156 - mae: 136842.0156 - val_loss: 137028.3750 - val_mae: 137028.3750\n",
      "Epoch 803/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 135468.5156 - mae: 135468.5156 - val_loss: 141900.8125 - val_mae: 141900.8125\n",
      "Epoch 804/10000\n",
      "32/32 [==============================] - 0s 980us/step - loss: 136815.9219 - mae: 136815.9219 - val_loss: 139759.5781 - val_mae: 139759.5781\n",
      "Epoch 805/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139472.2656 - mae: 139472.2656 - val_loss: 138933.7969 - val_mae: 138933.7969\n",
      "Epoch 806/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134785.4688 - mae: 134785.4688 - val_loss: 137251.9844 - val_mae: 137251.9844\n",
      "Epoch 807/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141386.7812 - mae: 141386.7812 - val_loss: 137423.1250 - val_mae: 137423.1250\n",
      "Epoch 808/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136926.7031 - mae: 136926.7031 - val_loss: 139696.2969 - val_mae: 139696.2969\n",
      "Epoch 809/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138234.7969 - mae: 138234.7969 - val_loss: 138736.0469 - val_mae: 138736.0469\n",
      "Epoch 810/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140529.2188 - mae: 140529.2188 - val_loss: 160079.7812 - val_mae: 160079.7812\n",
      "Epoch 811/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 143285.1875 - mae: 143285.1875 - val_loss: 145356.1719 - val_mae: 145356.1719\n",
      "Epoch 812/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135146.8750 - mae: 135146.8750 - val_loss: 137730.9062 - val_mae: 137730.9062\n",
      "Epoch 813/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136946.4531 - mae: 136946.4531 - val_loss: 134182.7812 - val_mae: 134182.7812\n",
      "Epoch 814/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138629.8594 - mae: 138629.8594 - val_loss: 143963.8750 - val_mae: 143963.8750\n",
      "Epoch 815/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138960.7188 - mae: 138960.7188 - val_loss: 143952.9844 - val_mae: 143952.9844\n",
      "Epoch 816/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137547.7812 - mae: 137547.7812 - val_loss: 137670.9531 - val_mae: 137670.9531\n",
      "Epoch 817/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134336.5469 - mae: 134336.5469 - val_loss: 134889.8281 - val_mae: 134889.8281\n",
      "Epoch 818/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135119.5781 - mae: 135119.5781 - val_loss: 136864.6719 - val_mae: 136864.6719\n",
      "Epoch 819/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135819.9531 - mae: 135819.9531 - val_loss: 143021.7344 - val_mae: 143021.7344\n",
      "Epoch 820/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134988.0938 - mae: 134988.0938 - val_loss: 134480.3281 - val_mae: 134480.3281\n",
      "Epoch 821/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136761.5000 - mae: 136761.5000 - val_loss: 139769.0469 - val_mae: 139769.0469\n",
      "Epoch 822/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136245.9219 - mae: 136245.9219 - val_loss: 139889.5469 - val_mae: 139889.5469\n",
      "Epoch 823/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137249.0781 - mae: 137249.0781 - val_loss: 137245.4688 - val_mae: 137245.4688\n",
      "Epoch 824/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 136406.0469 - mae: 136406.0469 - val_loss: 137943.6406 - val_mae: 137943.6406\n",
      "Epoch 825/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135888.2969 - mae: 135888.2969 - val_loss: 140685.2656 - val_mae: 140685.2656\n",
      "Epoch 826/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137033.5781 - mae: 137033.5781 - val_loss: 141887.3594 - val_mae: 141887.3594\n",
      "Epoch 827/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139872.3438 - mae: 139872.3438 - val_loss: 143987.5781 - val_mae: 143987.5781\n",
      "Epoch 828/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138338.6406 - mae: 138338.6406 - val_loss: 142039.0625 - val_mae: 142039.0625\n",
      "Epoch 829/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135762.6250 - mae: 135762.6250 - val_loss: 143502.7188 - val_mae: 143502.7188\n",
      "Epoch 830/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137700.6250 - mae: 137700.6250 - val_loss: 142502.0469 - val_mae: 142502.0469\n",
      "Epoch 831/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137749.1562 - mae: 137749.1562 - val_loss: 138685.2812 - val_mae: 138685.2812\n",
      "Epoch 832/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137572.9219 - mae: 137572.9219 - val_loss: 149663.5000 - val_mae: 149663.5000\n",
      "Epoch 833/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136918.0781 - mae: 136918.0781 - val_loss: 142166.1250 - val_mae: 142166.1250\n",
      "Epoch 834/10000\n",
      "32/32 [==============================] - 0s 991us/step - loss: 141130.7812 - mae: 141130.7812 - val_loss: 137581.6094 - val_mae: 137581.6094\n",
      "Epoch 835/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136042.2344 - mae: 136042.2344 - val_loss: 138477.0156 - val_mae: 138477.0156\n",
      "Epoch 836/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134198.2188 - mae: 134198.2188 - val_loss: 140312.2344 - val_mae: 140312.2344\n",
      "Epoch 837/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139162.1406 - mae: 139162.1406 - val_loss: 148623.7500 - val_mae: 148623.7500\n",
      "Epoch 838/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138741.9844 - mae: 138741.9844 - val_loss: 139675.0625 - val_mae: 139675.0625\n",
      "Epoch 839/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135759.2500 - mae: 135759.2500 - val_loss: 142388.8750 - val_mae: 142388.8750\n",
      "Epoch 840/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136684.5781 - mae: 136684.5781 - val_loss: 136608.5469 - val_mae: 136608.5469\n",
      "Epoch 841/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137160.2500 - mae: 137160.2500 - val_loss: 136047.5312 - val_mae: 136047.5312\n",
      "Epoch 842/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136345.7188 - mae: 136345.7188 - val_loss: 136139.2656 - val_mae: 136139.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 843/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139655.8125 - mae: 139655.8125 - val_loss: 137420.7969 - val_mae: 137420.7969\n",
      "Epoch 844/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139310.2344 - mae: 139310.2344 - val_loss: 135126.2656 - val_mae: 135126.2656\n",
      "Epoch 845/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 137527.3125 - mae: 137527.3125 - val_loss: 141162.2344 - val_mae: 141162.2344\n",
      "Epoch 846/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136569.7812 - mae: 136569.7812 - val_loss: 141044.5312 - val_mae: 141044.5312\n",
      "Epoch 847/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 141352.8594 - mae: 141352.8594 - val_loss: 138591.5938 - val_mae: 138591.5938\n",
      "Epoch 848/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 136282.4844 - mae: 136282.4844 - val_loss: 140956.1094 - val_mae: 140956.1094\n",
      "Epoch 849/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134820.6250 - mae: 134820.6250 - val_loss: 139796.1094 - val_mae: 139796.1094\n",
      "Epoch 850/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137282.5156 - mae: 137282.5156 - val_loss: 137748.8750 - val_mae: 137748.8750\n",
      "Epoch 851/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135067.8906 - mae: 135067.8906 - val_loss: 142097.3906 - val_mae: 142097.3906\n",
      "Epoch 852/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 136127.4531 - mae: 136127.4531 - val_loss: 147286.0938 - val_mae: 147286.0938\n",
      "Epoch 853/10000\n",
      "32/32 [==============================] - 0s 984us/step - loss: 138096.5156 - mae: 138096.5156 - val_loss: 145324.1250 - val_mae: 145324.1250\n",
      "Epoch 854/10000\n",
      "32/32 [==============================] - 0s 990us/step - loss: 136707.9375 - mae: 136707.9375 - val_loss: 139716.8594 - val_mae: 139716.8594\n",
      "Epoch 855/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140284.0156 - mae: 140284.0156 - val_loss: 146615.8281 - val_mae: 146615.8281\n",
      "Epoch 856/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137419.0469 - mae: 137419.0469 - val_loss: 136409.2188 - val_mae: 136409.2188\n",
      "Epoch 857/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135064.0625 - mae: 135064.0625 - val_loss: 141594.2500 - val_mae: 141594.2500\n",
      "Epoch 858/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136189.6875 - mae: 136189.6875 - val_loss: 142637.7031 - val_mae: 142637.7031\n",
      "Epoch 859/10000\n",
      "32/32 [==============================] - 0s 980us/step - loss: 135389.8906 - mae: 135389.8906 - val_loss: 141510.3906 - val_mae: 141510.3906\n",
      "Epoch 860/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140688.9375 - mae: 140688.9375 - val_loss: 139120.2969 - val_mae: 139120.2969\n",
      "Epoch 861/10000\n",
      "32/32 [==============================] - 0s 998us/step - loss: 138855.3438 - mae: 138855.3438 - val_loss: 141242.9062 - val_mae: 141242.9062\n",
      "Epoch 862/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133764.3125 - mae: 133764.3125 - val_loss: 138174.1875 - val_mae: 138174.1875\n",
      "Epoch 863/10000\n",
      "32/32 [==============================] - 0s 997us/step - loss: 135639.9062 - mae: 135639.9062 - val_loss: 141493.5625 - val_mae: 141493.5625\n",
      "Epoch 864/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135038.3281 - mae: 135038.3281 - val_loss: 137860.5312 - val_mae: 137860.5312\n",
      "Epoch 865/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134689.7344 - mae: 134689.7344 - val_loss: 139206.8438 - val_mae: 139206.8438\n",
      "Epoch 866/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137818.8438 - mae: 137818.8438 - val_loss: 147909.8750 - val_mae: 147909.8750\n",
      "Epoch 867/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 140834.8438 - mae: 140834.8438 - val_loss: 140864.1250 - val_mae: 140864.1250\n",
      "Epoch 868/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137180.9844 - mae: 137180.9844 - val_loss: 148519.6562 - val_mae: 148519.6562\n",
      "Epoch 869/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135390.8281 - mae: 135390.8281 - val_loss: 146267.5781 - val_mae: 146267.5781\n",
      "Epoch 870/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 136059.8281 - mae: 136059.8281 - val_loss: 139449.5469 - val_mae: 139449.5469\n",
      "Epoch 871/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136233.3438 - mae: 136233.3438 - val_loss: 142133.6719 - val_mae: 142133.6719\n",
      "Epoch 872/10000\n",
      "32/32 [==============================] - 0s 995us/step - loss: 134410.4219 - mae: 134410.4219 - val_loss: 140401.0156 - val_mae: 140401.0156\n",
      "Epoch 873/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134961.4219 - mae: 134961.4219 - val_loss: 136562.9062 - val_mae: 136562.9062\n",
      "Epoch 874/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133860.8125 - mae: 133860.8125 - val_loss: 138110.7344 - val_mae: 138110.7344\n",
      "Epoch 875/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135826.7500 - mae: 135826.7500 - val_loss: 141324.4375 - val_mae: 141324.4375\n",
      "Epoch 876/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136643.8125 - mae: 136643.8125 - val_loss: 142478.4375 - val_mae: 142478.4375\n",
      "Epoch 877/10000\n",
      "32/32 [==============================] - 0s 995us/step - loss: 135848.7188 - mae: 135848.7188 - val_loss: 136849.8438 - val_mae: 136849.8438\n",
      "Epoch 878/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135353.3125 - mae: 135353.3125 - val_loss: 139760.0938 - val_mae: 139760.0938\n",
      "Epoch 879/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135023.7656 - mae: 135023.7656 - val_loss: 139776.2188 - val_mae: 139776.2188\n",
      "Epoch 880/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135787.3438 - mae: 135787.3438 - val_loss: 142146.8125 - val_mae: 142146.8125\n",
      "Epoch 881/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135547.8594 - mae: 135547.8594 - val_loss: 142395.6875 - val_mae: 142395.6875\n",
      "Epoch 882/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135735.3438 - mae: 135735.3438 - val_loss: 134241.8906 - val_mae: 134241.8906\n",
      "Epoch 883/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136699.5625 - mae: 136699.5625 - val_loss: 139225.3906 - val_mae: 139225.3906\n",
      "Epoch 884/10000\n",
      "32/32 [==============================] - 0s 993us/step - loss: 136159.8594 - mae: 136159.8594 - val_loss: 139531.8906 - val_mae: 139531.8906\n",
      "Epoch 885/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138311.3438 - mae: 138311.3438 - val_loss: 146493.6719 - val_mae: 146493.6719\n",
      "Epoch 886/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137532.4219 - mae: 137532.4219 - val_loss: 137719.7344 - val_mae: 137719.7344\n",
      "Epoch 887/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137103.3750 - mae: 137103.3750 - val_loss: 135627.7031 - val_mae: 135627.7031\n",
      "Epoch 888/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135977.3750 - mae: 135977.3750 - val_loss: 141237.5000 - val_mae: 141237.5000\n",
      "Epoch 889/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134170.7031 - mae: 134170.7031 - val_loss: 136121.8125 - val_mae: 136121.8125\n",
      "Epoch 890/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134281.5781 - mae: 134281.5781 - val_loss: 136734.9062 - val_mae: 136734.9062\n",
      "Epoch 891/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137809.8438 - mae: 137809.8438 - val_loss: 141732.0156 - val_mae: 141732.0156\n",
      "Epoch 892/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136862.7344 - mae: 136862.7344 - val_loss: 143268.4531 - val_mae: 143268.4531\n",
      "Epoch 893/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135963.2188 - mae: 135963.2188 - val_loss: 146054.8125 - val_mae: 146054.8125\n",
      "Epoch 894/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135554.2344 - mae: 135554.2344 - val_loss: 135164.6562 - val_mae: 135164.6562\n",
      "Epoch 895/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135650.2188 - mae: 135650.2188 - val_loss: 140878.9531 - val_mae: 140878.9531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138999.2031 - mae: 138999.2031 - val_loss: 141212.8906 - val_mae: 141212.8906\n",
      "Epoch 897/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134857.2344 - mae: 134857.2344 - val_loss: 139730.3438 - val_mae: 139730.3438\n",
      "Epoch 898/10000\n",
      "32/32 [==============================] - 0s 975us/step - loss: 134745.1406 - mae: 134745.1406 - val_loss: 136187.0781 - val_mae: 136187.0781\n",
      "Epoch 899/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138310.3906 - mae: 138310.3906 - val_loss: 138418.4531 - val_mae: 138418.4531\n",
      "Epoch 900/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134320.1094 - mae: 134320.1094 - val_loss: 139620.0625 - val_mae: 139620.0625\n",
      "Epoch 901/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134163.6562 - mae: 134163.6562 - val_loss: 140029.6250 - val_mae: 140029.6250\n",
      "Epoch 902/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134184.2656 - mae: 134184.2656 - val_loss: 137217.9531 - val_mae: 137217.9531\n",
      "Epoch 903/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133236.5781 - mae: 133236.5781 - val_loss: 138496.9062 - val_mae: 138496.9062\n",
      "Epoch 904/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135038.2188 - mae: 135038.2188 - val_loss: 143905.2812 - val_mae: 143905.2812\n",
      "Epoch 905/10000\n",
      "32/32 [==============================] - 0s 972us/step - loss: 137223.3125 - mae: 137223.3125 - val_loss: 140899.9375 - val_mae: 140899.9375\n",
      "Epoch 906/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133942.2344 - mae: 133942.2344 - val_loss: 142204.8750 - val_mae: 142204.8750\n",
      "Epoch 907/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 136386.3125 - mae: 136386.3125 - val_loss: 146026.3281 - val_mae: 146026.3281\n",
      "Epoch 908/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135803.5938 - mae: 135803.5938 - val_loss: 137724.7969 - val_mae: 137724.7969\n",
      "Epoch 909/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133393.7656 - mae: 133393.7656 - val_loss: 136390.7031 - val_mae: 136390.7031\n",
      "Epoch 910/10000\n",
      "32/32 [==============================] - 0s 984us/step - loss: 139925.9844 - mae: 139925.9844 - val_loss: 141916.5156 - val_mae: 141916.5156\n",
      "Epoch 911/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 133064.8438 - mae: 133064.8438 - val_loss: 135269.3594 - val_mae: 135269.3594\n",
      "Epoch 912/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137047.6094 - mae: 137047.6094 - val_loss: 139350.8594 - val_mae: 139350.8594\n",
      "Epoch 913/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136116.7812 - mae: 136116.7812 - val_loss: 141225.6250 - val_mae: 141225.6250\n",
      "Epoch 914/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133977.7188 - mae: 133977.7188 - val_loss: 137774.5312 - val_mae: 137774.5312\n",
      "Epoch 915/10000\n",
      "32/32 [==============================] - 0s 959us/step - loss: 134707.4844 - mae: 134707.4844 - val_loss: 141009.9844 - val_mae: 141009.9844\n",
      "Epoch 916/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133691.9688 - mae: 133691.9688 - val_loss: 139781.8750 - val_mae: 139781.8750\n",
      "Epoch 917/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139645.9531 - mae: 139645.9531 - val_loss: 134858.9531 - val_mae: 134858.9531\n",
      "Epoch 918/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136941.3594 - mae: 136941.3594 - val_loss: 140151.5000 - val_mae: 140151.5000\n",
      "Epoch 919/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 136214.3906 - mae: 136214.3906 - val_loss: 138565.6719 - val_mae: 138565.6719\n",
      "Epoch 920/10000\n",
      "32/32 [==============================] - 0s 994us/step - loss: 136973.3906 - mae: 136973.3906 - val_loss: 139431.0625 - val_mae: 139431.0625\n",
      "Epoch 921/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133712.5000 - mae: 133712.5000 - val_loss: 137257.7969 - val_mae: 137257.7969\n",
      "Epoch 922/10000\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 133929.7969 - mae: 133929.7969 - val_loss: 136393.4844 - val_mae: 136393.4844\n",
      "Epoch 923/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 132788.1250 - mae: 132788.1250 - val_loss: 143515.2344 - val_mae: 143515.2344\n",
      "Epoch 924/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134881.4219 - mae: 134881.4219 - val_loss: 144802.9844 - val_mae: 144802.9844\n",
      "Epoch 925/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133691.5156 - mae: 133691.5156 - val_loss: 138247.7969 - val_mae: 138247.7969\n",
      "Epoch 926/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133676.2188 - mae: 133676.2188 - val_loss: 138848.9844 - val_mae: 138848.9844\n",
      "Epoch 927/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 137644.9375 - mae: 137644.9375 - val_loss: 140656.8125 - val_mae: 140656.8125\n",
      "Epoch 928/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 138732.8125 - mae: 138732.8125 - val_loss: 151257.5312 - val_mae: 151257.5312\n",
      "Epoch 929/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 139217.2656 - mae: 139217.2656 - val_loss: 142160.7500 - val_mae: 142160.7500\n",
      "Epoch 930/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135328.1562 - mae: 135328.1562 - val_loss: 140915.1562 - val_mae: 140915.1562\n",
      "Epoch 931/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135309.7031 - mae: 135309.7031 - val_loss: 138463.2188 - val_mae: 138463.2188\n",
      "Epoch 932/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134298.6094 - mae: 134298.6094 - val_loss: 138377.7031 - val_mae: 138377.7031\n",
      "Epoch 933/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135285.4688 - mae: 135285.4688 - val_loss: 144767.0938 - val_mae: 144767.0938\n",
      "Epoch 934/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134867.1719 - mae: 134867.1719 - val_loss: 141078.0000 - val_mae: 141078.0000\n",
      "Epoch 935/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133226.7031 - mae: 133226.7031 - val_loss: 138257.4375 - val_mae: 138257.4375\n",
      "Epoch 936/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 132550.9062 - mae: 132550.9062 - val_loss: 137502.5781 - val_mae: 137502.5781\n",
      "Epoch 937/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133669.8594 - mae: 133669.8594 - val_loss: 138376.2656 - val_mae: 138376.2656\n",
      "Epoch 938/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133019.9688 - mae: 133019.9688 - val_loss: 139697.4375 - val_mae: 139697.4375\n",
      "Epoch 939/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133949.6562 - mae: 133949.6562 - val_loss: 143529.7344 - val_mae: 143529.7344\n",
      "Epoch 940/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133075.1875 - mae: 133075.1875 - val_loss: 138237.7344 - val_mae: 138237.7344\n",
      "Epoch 941/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133504.3438 - mae: 133504.3438 - val_loss: 137766.8125 - val_mae: 137766.8125\n",
      "Epoch 942/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134250.8438 - mae: 134250.8438 - val_loss: 140351.5312 - val_mae: 140351.5312\n",
      "Epoch 943/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 132965.4062 - mae: 132965.4062 - val_loss: 140298.5625 - val_mae: 140298.5625\n",
      "Epoch 944/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 133298.6406 - mae: 133298.6406 - val_loss: 142955.0312 - val_mae: 142955.0312\n",
      "Epoch 945/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135611.5469 - mae: 135611.5469 - val_loss: 142385.7344 - val_mae: 142385.7344\n",
      "Epoch 946/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 135110.7031 - mae: 135110.7031 - val_loss: 139117.9844 - val_mae: 139117.9844\n",
      "Epoch 947/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 132976.9062 - mae: 132976.9062 - val_loss: 139471.9062 - val_mae: 139471.9062\n",
      "Epoch 948/10000\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 134112.6250 - mae: 134112.6250 - val_loss: 138515.1562 - val_mae: 138515.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 949/10000\n",
      "\r",
      " 1/32 [..............................] - ETA: 0s - loss: 133154.2656 - mae: 133154.2656"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/deepagri/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1178\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1179\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1180\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1181\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1182\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1183\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1185\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/deepagri/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 889\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    892\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/deepagri/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/deepagri/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   3021\u001b[0m   (graph_function,\n\u001b[1;32m   3022\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/deepagri/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1956\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1959\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1962\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m     args,\n\u001b[1;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1965\u001b[0m     executing_eagerly)\n\u001b[1;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/deepagri/lib/python3.8/site-packages/tensorflow/python/eager/function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/deepagri/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=32,epochs=10000,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a5bed4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:50:11.996240Z",
     "start_time": "2022-03-04T14:50:11.943170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee61462c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:53:50.085910Z",
     "start_time": "2022-03-04T14:53:50.042174Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = np.asarray(X_test).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1b8c701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T14:53:56.647899Z",
     "start_time": "2022-03-04T14:53:56.599058Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = np.asarray(y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "525dae61",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
